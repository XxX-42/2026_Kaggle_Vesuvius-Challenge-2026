"""
Vesuvius Challenge 2026 - 3D æ•°æ®åŠ è½½å™¨
ç”¨äºå¤„ç† 3D TIF å·è½´æ•°æ®çš„ PyTorch Dataset ç±»

æ ¸å¿ƒåŠŸèƒ½ï¼š
- ä½¿ç”¨ tifffile è¯»å– 3D TIF volume
- RandomCrop æå–å›ºå®šå¤§å°çš„ Patch
- uint16 â†’ float32 å½’ä¸€åŒ–åˆ° [0, 1]
- è¾“å‡ºæ ¼å¼ï¼š(C=1, D, H, W)
"""

import os
import random
from pathlib import Path
from typing import Tuple, Optional, Callable

import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset
import tifffile


class VesuviusDataset(Dataset):
    """
    Vesuvius 3D å·è½´æ•°æ®é›†
    
    ä»å¤§å‹ 3D TIF Volume ä¸­éšæœºè£å‰ªå›ºå®šå¤§å°çš„ Patch ç”¨äºè®­ç»ƒã€‚
    
    Args:
        csv_path: train.csv æ–‡ä»¶è·¯å¾„ï¼ŒåŒ…å« id å’Œ scroll_id åˆ—
        image_root: å›¾åƒæ–‡ä»¶æ ¹ç›®å½•ï¼ˆåŒ…å« {id}.tif æ–‡ä»¶ï¼‰
        label_root: æ ‡ç­¾æ–‡ä»¶æ ¹ç›®å½•ï¼ˆåŒ…å« {id}.tif æ–‡ä»¶ï¼‰
        patch_size: 3D Patch å°ºå¯¸ (Depth, Height, Width)ï¼Œé»˜è®¤ (64, 128, 128)
        transform: å¯é€‰çš„æ•°æ®å¢å¼ºå‡½æ•°
    """
    
    def __init__(
        self,
        csv_path: str,
        image_root: str,
        label_root: str,
        patch_size: Tuple[int, int, int] = (64, 128, 128),
        transform: Optional[Callable] = None,
        mode: str = 'train',
        pos_ratio: float = 0.5  # [NEW] æ­£æ ·æœ¬é‡‡æ ·æ¯”ä¾‹
    ):
        self.image_root = Path(image_root)
        self.label_root = Path(label_root)
        self.patch_size = patch_size  # (D, H, W)
        self.transform = transform
        self.mode = mode
        self.pos_ratio = pos_ratio
        
        # [CRITICAL UPDATE] é˜ˆå€¼ä»1500é™åˆ°300ä»¥è§£é™¤IOç“¶é¢ˆ (é€Ÿåº¦ä¼˜å…ˆ)
        self.rejection_threshold = 300
        self.max_retries = 20
        
        # ====== è‡ªåŠ¨æ£€æµ‹ NPY ç›®å½• ======
        # å‡è®¾ NPY ç›®å½•åä¸º {root}_npyï¼Œä¾‹å¦‚ train_images_npy
        self.npy_image_root = self.image_root.parent / (self.image_root.name + "_npy")
        self.npy_label_root = self.label_root.parent / (self.label_root.name + "_npy")
        
        self.use_npy = False
        if self.npy_image_root.exists() and self.npy_label_root.exists():
            self.use_npy = True
            print(f"[Dataset] ğŸš€ å‘ç°é¢„å¤„ç† NPY æ•°æ®ï¼Œå¯ç”¨æé€Ÿ mmap æ¨¡å¼ï¼")
            print(f"          Image: {self.npy_image_root}")
            print(f"          Label: {self.npy_label_root}")
        else:
            print(f"[Dataset] æœªæ‰¾åˆ° NPY ç›®å½•ï¼Œå›é€€åˆ° TIF æ¨¡å¼ (IO è¾ƒæ…¢)")
            print(f"          Image: {self.image_root}")
            print(f"          Label: {self.label_root}")
        
        # è¯»å– CSV å¹¶éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§
        self.df = pd.read_csv(csv_path)
        self._validate_files()
        
        print(f"[VesuviusDataset] åˆå§‹åŒ–å®Œæˆï¼šå…± {len(self.df)} ä¸ªæ ·æœ¬ (mode={mode})")
        print(f"[VesuviusDataset] Patch å°ºå¯¸ï¼š{patch_size} (D, H, W)")
        print(f"[VesuviusDataset] Sampling Strategy: Surface-Biased (pos_ratio={pos_ratio})")
    
    def _validate_files(self) -> None:
        """éªŒè¯æ‰€æœ‰æ ·æœ¬çš„å›¾åƒå’Œæ ‡ç­¾æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œè¿‡æ»¤æ‰ç¼ºå¤±çš„æ ·æœ¬"""
        valid_indices = []
        missing_count = 0
        
        for idx, row in self.df.iterrows():
            sample_id = row['id']
            image_path = self.image_root / f"{sample_id}.tif"
            label_path = self.label_root / f"{sample_id}.tif"
            
            if image_path.exists() and label_path.exists():
                valid_indices.append(idx)
            else:
                missing_count += 1
        
        if missing_count > 0:
            print(f"[VesuviusDataset] è­¦å‘Šï¼šå‘ç° {missing_count} ä¸ªç¼ºå¤±æ–‡ä»¶ï¼Œå·²è‡ªåŠ¨è¿‡æ»¤")
        
        # åªä¿ç•™æœ‰æ•ˆæ ·æœ¬
        self.df = self.df.loc[valid_indices].reset_index(drop=True)
    
    def __len__(self) -> int:
        return len(self.df)
    
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        è·å–ä¸€ä¸ªè®­ç»ƒæ ·æœ¬
        
        NPY æ¨¡å¼ä¼˜åŒ–:
        - _load_data è¿”å› mmap å¯¹è±¡ (é›¶æ‹·è´)
        - _surface_biased_crop è¿›è¡Œåˆ‡ç‰‡ (åªè¯»å– Patch æ•°æ®)
        - è½¬æ¢ä¸º float32 å¹¶å½’ä¸€åŒ–
        """
        sample_id = self.df.iloc[idx]['id']
        
        # 1. åŠ è½½æ•°æ® (NPY mmap æˆ– TIF)
        image_vol, label_vol = self._load_data(str(sample_id))
        
        # 2. é‡‡æ ·è£åˆ‡ (Surface-Biased)
        # ä¼ å…¥çš„æ˜¯æ•´ä¸ª Volume (æˆ– mmap)ï¼Œåœ¨å†…éƒ¨è¿›è¡Œåˆ‡ç‰‡è¯»å–
        image, label = self._surface_biased_crop(image_vol, label_vol)
        
        # 3. è½¬æ¢ä¸º float32 å¹¶å½’ä¸€åŒ– (image: [0, 1])
        # æ³¨æ„ï¼šmmap åˆ‡ç‰‡åå¾—åˆ°çš„æ˜¯ numpy arrayï¼Œæ­¤æ—¶æ•°æ®å·²åœ¨äºå†…å­˜ä¸­
        image = self._normalize(image)
        # label = self._normalize(label) # åºŸå¼ƒæ—§é€»è¾‘, label ä¿æŒåŸå§‹å€¼åç»­åšäºŒå€¼åŒ–
        
        # [P0 FIX] ç«èµ›æ ‡ç­¾å®šä¹‰ï¼š0=èƒŒæ™¯, 1=çº¸è‰è¡¨é¢(ç›®æ ‡), 2=å¿½ç•¥åŒºåŸŸ
        # 1. ç”Ÿæˆæœ‰æ•ˆæ€§ Mask (Valid Mask)ï¼šval != 2 çš„åŒºåŸŸä¸ºæœ‰æ•ˆ (1.0)ï¼Œval == 2 ä¸ºæ— æ•ˆ (0.0)
        valid_mask = (label != 2).astype(np.float32)
        
        # 2. ç”ŸæˆäºŒå€¼ Labelï¼šåªè®¤ val=1 ä¸ºæ­£æ ·æœ¬ï¼Œval=2 ä¸ºå¿½ç•¥åŒºåŸŸï¼ˆå½“ä½œèƒŒæ™¯å¤„ç†ï¼‰
        label = (label == 1).astype(np.float32)
        
        # [P3] å½¢æ€å­¦é—­è¿ç®—æ¸…æ´—ï¼ˆå¯é€‰ï¼Œé»˜è®¤å…³é—­ä»¥ä¿æ€§èƒ½ï¼‰
        # å¯ç”¨æ–¹å¼: VesuviusDataset(..., clean_labels=True)
        if getattr(self, 'clean_labels', False):
            from src.mask_cleaning import clean_mask
            label = clean_mask(label, closing_radius=1, anisotropic=True).astype(np.float32)
        
        # è½¬æ¢ä¸º PyTorch å¼ é‡å¹¶æ·»åŠ  Channel ç»´åº¦
        image = torch.from_numpy(image).float().unsqueeze(0)  # (1, D, H, W)
        label = torch.from_numpy(label).float().unsqueeze(0)  # (1, D, H, W)
        valid_mask = torch.from_numpy(valid_mask).float().unsqueeze(0) # (1, D, H, W)
        
        # [CRITICAL DECISION] å°† label å’Œ valid_mask æ‹¼æ¥ï¼Œä¼ é€’ç»™ transform
        # label shape: (2, D, H, W) -> Channel 0: Label, Channel 1: ValidMask
        label = torch.cat([label, valid_mask], dim=0)
        
        # åº”ç”¨æ•°æ®å¢å¼º (transform é€šå¸¸èƒ½å¤„ç†å¤šé€šé“ label)
        if self.transform is not None:
            image, label = self.transform(image, label)
        
        return image, label
    
    def _load_data(self, sample_id: str) -> Tuple[np.ndarray, np.ndarray]:
        """ç»Ÿä¸€åŠ è½½æ•°æ® (NPY mmap æˆ– TIF è¯»å–)"""
        if self.use_npy:
            img_path = self.npy_image_root / f"{sample_id}.npy"
            lbl_path = self.npy_label_root / f"{sample_id}.npy"
            # mmap_mode='r' é›¶æ‹·è´ï¼Œæé€Ÿæ‰“å¼€
            image = np.load(img_path, mmap_mode='r')
            label = np.load(lbl_path, mmap_mode='r')
        else:
            img_path = self.image_root / f"{sample_id}.tif"
            lbl_path = self.label_root / f"{sample_id}.tif"
            image = tifffile.imread(str(img_path))
            label = tifffile.imread(str(lbl_path))
            
        return image, label

    def _surface_biased_crop(
        self, 
        image: np.ndarray, 
        label: np.ndarray
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        Surface-Biased Sampling (è¡¨é¢åç½®é‡‡æ ·)
        
        ç­–ç•¥:
        1. ä»¥ pos_ratio çš„æ¦‚ç‡å¼ºåˆ¶é‡‡æ ·åŒ…å«æ­£æ ·æœ¬ (val=1) çš„ Patchã€‚
        2. å‰©ä½™æ¦‚ç‡è¿›è¡Œéšæœºé‡‡æ · (è´Ÿæ ·æœ¬æŒ–æ˜)ã€‚
        
        ä¼˜åŒ–:
        - é’ˆå¯¹ mmap æ•°ç»„ï¼Œå…ˆåˆ‡ç‰‡å†æ£€æŸ¥ï¼Œé¿å…å…¨é‡ I/Oã€‚
        - ä½¿ç”¨ buffer é¿å…è¾¹ç•Œæº¢å‡ºã€‚
        """
        d, h, w = image.shape
        pd, ph, pw = self.patch_size
        
        # å¡«å…… (å¦‚æœ volume å°äº patch)
        if d < pd or h < ph or w < pw:
            # å¯¹äº mmapï¼Œæˆ‘ä»¬éœ€è¦å…ˆè¯»å‡ºæ¥å† pad (ä¼šè§¦å‘ IO)
            # ä½†é€šå¸¸ volume å¾ˆå¤§ã€‚è¿™é‡Œä¸ºäº†å®‰å…¨ï¼Œå¦‚æœæ˜¯ mmap ä¸”è¿™å°±å‘ç”Ÿäº†ï¼Œ
            # å¯èƒ½éœ€è¦ç‰¹æ®Šå¤„ç†ã€‚ç®€å•èµ·è§ï¼Œè½¬ä¸º numpy array (IO cost incurred)
            if isinstance(image, np.memmap):
                image = np.array(image)
                label = np.array(label)
                
            pad_d = max(0, pd - d)
            pad_h = max(0, ph - h)
            pad_w = max(0, pw - w)
            image = np.pad(image, ((0, pad_d), (0, pad_h), (0, pad_w)), mode='constant')
            label = np.pad(label, ((0, pad_d), (0, pad_h), (0, pad_w)), mode='constant')
            d, h, w = image.shape
            
        # å†³å®šæ˜¯å¦å¼ºåˆ¶é‡‡æ ·æ­£æ ·æœ¬
        force_positive = (random.random() < self.pos_ratio)
        
        for attempt in range(self.max_retries):
            # éšæœºåæ ‡
            sd = random.randint(0, d - pd)
            sh = random.randint(0, h - ph)
            sw = random.randint(0, w - pw)
            
            # [Optimization] å¦‚æœæ˜¯å¼ºåˆ¶æ­£æ ·æœ¬æ¨¡å¼ï¼Œå…ˆåªåˆ‡ label æ£€æŸ¥
            if force_positive:
                # åˆ‡ç‰‡ (è‹¥ä¸º mmapï¼Œæ­¤æ—¶ä»…è¯»å– meta infoï¼Œä¸è¯»å–æ•°æ®?)
                # å®é™…ä¸Š np.sum æˆ– np.any ä¼šè§¦å‘è¯»å–ã€‚
                # åˆ‡å–å°å— patch è¯»å–å¼€é”€å¾ˆå° (~0.5MB)ã€‚
                lbl_patch = label[sd:sd+pd, sh:sh+ph, sw:sw+pw]
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«æ­£æ ·æœ¬ (val=1)
                # æ³¨æ„ï¼šåŸå§‹ label å¯èƒ½åŒ…å« 0, 1, 2
                # æˆ‘ä»¬å¯»æ‰¾ val=1 çš„åŒºåŸŸ
                if np.any(lbl_patch == 1):
                    # æ‰¾åˆ°äº†ï¼è¯»å– image å¹¶è¿”å›
                    img_patch = image[sd:sd+pd, sh:sh+ph, sw:sw+pw]
                    return img_patch, lbl_patch
            else:
                # éšæœºæ¨¡å¼ (è´Ÿæ ·æœ¬æŒ–æ˜)ï¼Œç›´æ¥æ¥å—
                img_patch = image[sd:sd+pd, sh:sh+ph, sw:sw+pw]
                lbl_patch = label[sd:sd+pd, sh:sh+ph, sw:sw+pw]
                return img_patch, lbl_patch
        
        # å¦‚æœé‡è¯•å¤šæ¬¡ä»æœªæ‰¾åˆ°æ­£æ ·æœ¬ï¼Œé€€åŒ–ä¸ºéšæœºé‡‡æ ·
        img_patch = image[sd:sd+pd, sh:sh+ph, sw:sw+pw]
        lbl_patch = label[sd:sd+pd, sh:sh+ph, sw:sw+pw]
        return img_patch, lbl_patch
    
    def _normalize(self, data: np.ndarray) -> np.ndarray:
        """
        å°†æ•°æ®å½’ä¸€åŒ–åˆ° [0, 1] èŒƒå›´
        
        [P0 FIX] ä¸å†ä¾èµ– max_val å¯å‘å¼åˆ¤æ–­ dtypeï¼Œ
        ç›´æ¥æ ¹æ®åŸå§‹ dtype ç¡®å®šå½’ä¸€åŒ–ç³»æ•°ï¼Œé¿å…è¾¹ç•Œæƒ…å†µã€‚
        """
        original_dtype = data.dtype
        data = data.astype(np.float32)
        
        # æ ¹æ®åŸå§‹ dtype é€‰æ‹©å½’ä¸€åŒ–ç³»æ•°
        if original_dtype == np.uint16:
            data = data / 65535.0
        elif original_dtype == np.uint8:
            data = data / 255.0
        # float32 / float64: å‡è®¾å·²ç»å½’ä¸€åŒ–ï¼Œä¸å¤„ç†
        
        return data



def create_dataloader(
    csv_path: str,
    image_root: str,
    label_root: str,
    batch_size: int = 4,
    patch_size: Tuple[int, int, int] = (64, 128, 128),
    num_workers: int = 4,
    shuffle: bool = True,
    transform: Optional[Callable] = None
) -> torch.utils.data.DataLoader:
    """
    åˆ›å»º DataLoader çš„ä¾¿æ·å‡½æ•°
    
    Args:
        csv_path: train.csv æ–‡ä»¶è·¯å¾„
        image_root: å›¾åƒæ–‡ä»¶æ ¹ç›®å½•
        label_root: æ ‡ç­¾æ–‡ä»¶æ ¹ç›®å½•
        batch_size: æ‰¹æ¬¡å¤§å°
        patch_size: 3D Patch å°ºå¯¸ (D, H, W)
        num_workers: æ•°æ®åŠ è½½çº¿ç¨‹æ•°
        shuffle: æ˜¯å¦æ‰“ä¹±æ•°æ®
        transform: å¯é€‰çš„æ•°æ®å¢å¼ºå‡½æ•°
    
    Returns:
        DataLoader å®ä¾‹
    """
    dataset = VesuviusDataset(
        csv_path=csv_path,
        image_root=image_root,
        label_root=label_root,
        patch_size=patch_size,
        transform=transform
    )
    
    dataloader = torch.utils.data.DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        pin_memory=True
    )
    
    return dataloader


if __name__ == "__main__":
    # ç®€å•æµ‹è¯•
    print("æµ‹è¯• VesuviusDataset...")
    
    # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼ˆä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼‰
    csv_path = "data/vesuvius-challenge-surface-detection/train.csv"
    image_root = "data/vesuvius-challenge-surface-detection/train_images"
    label_root = "data/vesuvius-challenge-surface-detection/train_labels"
    
    try:
        dataset = VesuviusDataset(
            csv_path=csv_path,
            image_root=image_root,
            label_root=label_root,
            patch_size=(64, 128, 128)
        )
        
        print(f"æ•°æ®é›†å¤§å°: {len(dataset)}")
        
        # è·å–ä¸€ä¸ªæ ·æœ¬
        image, label = dataset[0]
        print(f"å›¾åƒ shape: {image.shape}, dtype: {image.dtype}")
        print(f"æ ‡ç­¾ shape: {label.shape}, dtype: {label.dtype}")
        print(f"å›¾åƒå€¼èŒƒå›´: [{image.min():.4f}, {image.max():.4f}]")
        print(f"æ ‡ç­¾å€¼èŒƒå›´: [{label.min():.4f}, {label.max():.4f}]")
        
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {e}")
