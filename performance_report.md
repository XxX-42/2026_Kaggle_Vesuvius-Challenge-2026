# 🚀 训练瓶颈审查与优化报告

## 📊 当前性能诊断
*   **速度**: ~8.6s/batch (极慢)
*   **GPU 利用率**: 0.4GB / 6.0GB (严重闲置，<10%)
*   **IO 模式**: 实时解压 LZW TIF (CPU 密集) + 随机读取
*   **瓶颈定位**: **磁盘 IO 与 TIF 解压阻塞**

## 🛑 核心问题分析

### 1. 单线程 IO 阻塞 (致命)
当前 `train.py` 默认 `num_workers=0`。
*   **后果**: 数据加载与 GPU 计算是**串行**的。
*   **流程**: CPU 读硬盘 -> CPU 解压 TIF -> CPU 增强 -> GPU 等待 -> GPU 计算 (几毫秒) -> CPU 读硬盘...
*   GPU 99% 的时间在等 CPU 给数据。

### 2. TIF 格式不适合训练
原始数据是 `LZW` 压缩的 TIF。
*   **后果**: 无法使用 `memmap` (内存映射) 进行零拷贝读取。每次读取必须将整个 320³ 体积完整读入内存并解压，即使只需要一个 96³ 的小块。
*   **开销**: 每次 Cache Miss 带来 ~100ms+ 的解压延迟，且不可并行。

### 3. Cache 失效 (随机访问)
*   **后果**: `DataLoader(shuffle=True)` 会打乱所有样本。虽然 Cache 能存 200 个体积，但 786 个体积的随机访问导致 Cache 命中率极其不稳定。在 Windows 多进程下，Cache 更是无法跨进程共享，进一步降低效率。

---

## ⚡ 优化方案 (性能提升 10x-100x)

### 方案 A: 预处理为非压缩格式 (⭐ 强烈推荐 - 彻底解决)
将所有 TIF 转存为未压缩的 `.npy` 文件。
*   **原理**: `.npy` 支持 `mmap_mode='r'`，操作系统可以直接从硬盘只读取需要的 96³ 字节，**零 CPU 解压开销**。
*   **空间**: 786 * 32MB ≈ 25GB (硬盘换速度)。
*   **预期速度**: <0.1s/batch。

### 方案 B: 开启多进程数据加载 (快速尝试)
*   **操作**: 训练时加参数 `--num_workers 4`。
*   **风险**: Windows 下多进程内存开销可能翻倍 (Copy-on-Write 机制较弱)，且 Cache 被隔离。但能并行掩盖 IO 延迟。

### 方案 C: 内存暴力全加载 (如果你有 >32GB RAM)
*   **操作**: `--cache_size 786`。
*   **原理**: 开局此时慢，但第一轮 Epoch 后所有数据在内存，IO 归零。

---

## 🛠️ 执行计划 (推荐方案 A)

我已准备好 `preprocess_data.py` 脚本和适配后的 `dataset.py`。
**建议立即执行预处理 (耗时约 2 分钟)，然后飞速训练。**

是否执行方案 A？
