# Project Architecture: 20_src

## Directory Tree (Filtered)
```text
20_src/
â”œâ”€â”€ 20_data
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dataset.py
â”‚   â””â”€â”€ transforms.py
â”œâ”€â”€ 20_model
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ chimera_loss.py
â”‚   â””â”€â”€ dual_unet.py
â”œâ”€â”€ 20_src_code_only.md
â”œâ”€â”€ AUDIT_REPORT_2026.md
â”œâ”€â”€ __init__.py
â”œâ”€â”€ aggregate.py
â”œâ”€â”€ graph_builder.py
â”œâ”€â”€ output
â”‚   â”œâ”€â”€ chimera_run_20260214_031947_gpu_nf16
â”‚   â”œâ”€â”€ chimera_run_20260214_032021_gpu_nf16
â”‚   â”‚   â”œâ”€â”€ 1004283650_mask.tif
â”‚   â”‚   â”œâ”€â”€ 1006462223_mask.tif
â”‚   â”‚   â”œâ”€â”€ 1013184726_mask.tif
â”‚   â”‚   â”œâ”€â”€ 102536988_mask.tif
â”‚   â”‚   â””â”€â”€ 1029212680_mask.tif
â”‚   â”œâ”€â”€ inference_20260214_031445
â”‚   â”œâ”€â”€ train_20260214_033543
â”‚   â”‚   â”œâ”€â”€ best_model.pth
â”‚   â”‚   â””â”€â”€ training_history.json
â”‚   â”œâ”€â”€ train_20260214_034217
â”‚   â”œâ”€â”€ train_20260214_034358
â”‚   â”œâ”€â”€ train_20260214_034543
â”‚   â”œâ”€â”€ train_20260214_034653
â”‚   â”œâ”€â”€ train_20260214_034843
â”‚   â”œâ”€â”€ train_20260214_035035
â”‚   â”œâ”€â”€ train_20260214_035705
â”‚   â”œâ”€â”€ train_20260214_035932
â”‚   â”œâ”€â”€ train_20260214_040039
â”‚   â”œâ”€â”€ train_20260214_040137
â”‚   â”œâ”€â”€ train_20260214_041118
â”‚   â”œâ”€â”€ train_20260214_041247
â”‚   â”œâ”€â”€ train_20260214_041622
â”‚   â”‚   â”œâ”€â”€ best_model.pth
â”‚   â”‚   â”œâ”€â”€ epoch_masks
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch001_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch002_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch003_pred_mask.tif
â”‚   â”‚   â”‚   â””â”€â”€ epoch004_pred_mask.tif
â”‚   â”‚   â””â”€â”€ epoch_vis
â”‚   â”‚       â”œâ”€â”€ epoch001_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch001_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch002_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch002_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch003_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch003_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch004_3d_comparison.png
â”‚   â”‚       â””â”€â”€ epoch004_comparison.png
â”‚   â”œâ”€â”€ train_20260214_044912
â”‚   â”œâ”€â”€ train_20260214_050229
â”‚   â”‚   â”œâ”€â”€ best_model.pth
â”‚   â”‚   â”œâ”€â”€ epoch_masks
â”‚   â”‚   â”‚   â””â”€â”€ epoch001_pred_mask.tif
â”‚   â”‚   â””â”€â”€ epoch_vis
â”‚   â”‚       â”œâ”€â”€ epoch001_3d_comparison.png
â”‚   â”‚       â””â”€â”€ epoch001_comparison.png
â”‚   â”œâ”€â”€ train_20260214_050630
â”‚   â”‚   â”œâ”€â”€ best_model.pth
â”‚   â”‚   â”œâ”€â”€ epoch_masks
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch001_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch002_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch003_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch004_pred_mask.tif
â”‚   â”‚   â”‚   â””â”€â”€ epoch005_pred_mask.tif
â”‚   â”‚   â””â”€â”€ epoch_vis
â”‚   â”‚       â”œâ”€â”€ epoch001_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch001_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch002_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch002_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch003_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch003_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch004_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch004_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch005_3d_comparison.png
â”‚   â”‚       â””â”€â”€ epoch005_comparison.png
â”‚   â”œâ”€â”€ train_20260214_052733
â”‚   â”‚   â”œâ”€â”€ best_model.pth
â”‚   â”‚   â”œâ”€â”€ checkpoint_epoch010.pth
â”‚   â”‚   â”œâ”€â”€ epoch_masks
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch001_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch002_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch003_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch004_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch005_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch006_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch007_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch008_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch009_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch010_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch011_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch012_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch013_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch014_pred_mask.tif
â”‚   â”‚   â”‚   â””â”€â”€ epoch015_pred_mask.tif
â”‚   â”‚   â””â”€â”€ epoch_vis
â”‚   â”‚       â”œâ”€â”€ epoch001_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch001_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch002_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch002_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch003_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch003_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch004_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch004_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch005_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch005_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch006_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch006_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch007_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch007_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch008_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch008_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch009_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch009_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch010_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch010_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch011_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch011_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch012_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch012_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch013_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch013_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch014_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch014_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch015_3d_comparison.png
â”‚   â”‚       â””â”€â”€ epoch015_comparison.png
â”‚   â”œâ”€â”€ train_20260214_061413
â”‚   â”‚   â”œâ”€â”€ best_model.pth
â”‚   â”‚   â”œâ”€â”€ epoch_masks
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch001_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch002_pred_mask.tif
â”‚   â”‚   â”‚   â””â”€â”€ epoch003_pred_mask.tif
â”‚   â”‚   â””â”€â”€ epoch_vis
â”‚   â”‚       â”œâ”€â”€ epoch001_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch001_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch002_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch002_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch003_3d_comparison.png
â”‚   â”‚       â””â”€â”€ epoch003_comparison.png
â”‚   â”œâ”€â”€ train_20260214_063047
â”‚   â”‚   â”œâ”€â”€ best_model.pth
â”‚   â”‚   â”œâ”€â”€ checkpoint_epoch010.pth
â”‚   â”‚   â”œâ”€â”€ epoch_masks
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch001_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch002_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch003_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch004_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch005_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch006_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch007_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch008_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch009_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch010_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch011_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch012_pred_mask.tif
â”‚   â”‚   â”‚   â””â”€â”€ epoch013_pred_mask.tif
â”‚   â”‚   â””â”€â”€ epoch_vis
â”‚   â”‚       â”œâ”€â”€ epoch001_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch001_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch002_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch002_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch003_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch003_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch004_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch004_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch005_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch005_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch006_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch006_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch007_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch007_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch008_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch008_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch009_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch009_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch010_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch010_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch011_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch011_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch012_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch012_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch013_3d_comparison.png
â”‚   â”‚       â””â”€â”€ epoch013_comparison.png
â”‚   â”œâ”€â”€ train_20260214_071306
â”‚   â”œâ”€â”€ train_20260214_071429
â”‚   â”œâ”€â”€ train_20260214_071458
â”‚   â”œâ”€â”€ train_20260214_071514
â”‚   â”‚   â”œâ”€â”€ best_model.pth
â”‚   â”‚   â”œâ”€â”€ epoch_masks
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch001_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch002_pred_mask.tif
â”‚   â”‚   â”‚   â””â”€â”€ epoch003_pred_mask.tif
â”‚   â”‚   â””â”€â”€ epoch_vis
â”‚   â”‚       â”œâ”€â”€ epoch001_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch001_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch002_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch002_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch003_3d_comparison.png
â”‚   â”‚       â””â”€â”€ epoch003_comparison.png
â”‚   â”œâ”€â”€ train_20260214_072332
â”‚   â”‚   â”œâ”€â”€ best_model.pth
â”‚   â”‚   â”œâ”€â”€ epoch_masks
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch001_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch002_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch003_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch004_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch005_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch006_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch007_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch008_pred_mask.tif
â”‚   â”‚   â”‚   â””â”€â”€ epoch009_pred_mask.tif
â”‚   â”‚   â””â”€â”€ epoch_vis
â”‚   â”‚       â”œâ”€â”€ epoch001_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch001_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch002_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch002_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch003_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch003_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch004_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch004_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch005_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch005_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch006_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch006_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch007_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch007_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch008_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch008_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch009_3d_comparison.png
â”‚   â”‚       â””â”€â”€ epoch009_comparison.png
â”‚   â”œâ”€â”€ train_20260214_074649
â”‚   â”œâ”€â”€ train_20260214_074853
â”‚   â”‚   â”œâ”€â”€ best_model.pth
â”‚   â”‚   â”œâ”€â”€ epoch_masks
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch001_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch002_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch003_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch004_pred_mask.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch005_pred_mask.tif
â”‚   â”‚   â”‚   â””â”€â”€ epoch006_pred_mask.tif
â”‚   â”‚   â””â”€â”€ epoch_vis
â”‚   â”‚       â”œâ”€â”€ epoch001_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch001_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch002_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch002_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch003_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch003_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch004_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch004_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch005_3d_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch005_comparison.png
â”‚   â”‚       â”œâ”€â”€ epoch006_3d_comparison.png
â”‚   â”‚       â””â”€â”€ epoch006_comparison.png
â”‚   â””â”€â”€ verification_slice.png
â”œâ”€â”€ preprocess.py
â”œâ”€â”€ run_inference.py
â”œâ”€â”€ submission.py
â”œâ”€â”€ train.py
â”œâ”€â”€ verify_data.py
â””â”€â”€ winding_solver.py
```

---

## File: AUDIT_REPORT_2026.md
```md
# 2026 Kaggle Vesuvius Challenge - æ·±åº¦ä»£ç å®¡è®¡æŠ¥å‘Š

**å®¡è®¡å¯¹è±¡**: å½“å‰å·¥ä½œåŒº (Version 20_src)
**å®¡è®¡ä¸“å®¶**: Antigravity (Google Deepmind Agent)
**æ—¥æœŸ**: 2026-02-14

---

## ğŸ›‘ å®¡è®¡ç»“è®ºæ€»è§ˆ

ç»è¿‡å¯¹ `20_model/chimera_loss.py`, `20_model/dual_unet.py`, `20_src/winding_solver.py`, `20_src/run_inference.py` çš„æ·±åº¦å®¡æŸ¥ï¼Œå‘ç°ä»¥ä¸‹ **è‡´å‘½éšæ‚£ (Critical Issues)**ï¼š

1.  **[CRITICAL] è™šæ— ä¸»ä¹‰é™·é˜± (All-Ones/Zeros Trap)**
    *   **ç°è±¡**: Batch 100/150 å‡ºç° `Pred_Pixels=0.0`ï¼ŒéªŒè¯é›† Dice æ¥è¿‘ 0ã€‚
    *   **æ ¹æº**: `ChimeraLoss` ä¸­çš„ BCE Loss æœªåŠ æƒã€‚ç”±äºæ­£æ ·æœ¬ç¨€ç–åº¦ < 1%ï¼Œæ ‡å‡† BCE å¯¼è‡´èƒŒæ™¯ï¼ˆ0ï¼‰çš„æ¢¯åº¦å‹å€’äº†å‰æ™¯ï¼ˆ1ï¼‰ã€‚æ¨¡å‹å­¦ä¼šâ€œå…¨é¢„æµ‹ 0â€å³å¯è·å¾—æä½çš„ Loss (0.01 å·¦å³)ã€‚
    *   **ä¿®å¤**: å¿…é¡»å¼•å…¥ `pos_weight` (å»ºè®® 100.0) æˆ–åˆ‡æ¢ä¸º Focal Lossã€‚

2.  **[CRITICAL] Zè½´åˆ†è¾¨ç‡å´©æºƒ (Sensor Resolution Collapse)**
    *   **ç°è±¡**: çº¸è‰åšåº¦ä»… 1-3 ä½“ç´ ï¼Œä½†ç½‘ç»œæœ‰ 4 å±‚ `MaxPool3d(2)`ã€‚
    *   **æ ¹æº**: 4 å±‚ä¸‹é‡‡æ ·å°† Z è½´åˆ†è¾¨ç‡é™ä½ 16 å€ ($2^4$)ã€‚å¯¹äº 64 å±‚çš„ Chunkï¼ŒBottom å±‚åªæœ‰ 4 å±‚ç‰¹å¾ã€‚å¯¹äº 30 å±‚çš„ Chunkï¼Œç‰¹å¾å›¾åœ¨ Z è½´ä¸Šä»…å‰© 1-2 åƒç´ ï¼Œè¿™åœ¨ç‰©ç†ä¸ŠæŠ¹é™¤äº†çº¸è‰å’Œæ³•çº¿çš„ä»»ä½•å¾®è§‚ç»“æ„ã€‚
    *   **ä¿®å¤**: è¿™é‡Œçš„ MaxPool å¿…é¡»æ”¹ä¸ºå„å‘å¼‚æ€§ (Anisotropic)ï¼š`kernel_size=(1, 2, 2)`ï¼Œä»…åœ¨ XY å¹³é¢ä¸‹é‡‡æ ·ï¼Œä¿ç•™ Z è½´åˆ†è¾¨ç‡ã€‚

3.  **[HIGH] Winding Solver æ‹“æ‰‘æ–­è£‚é£é™©**
    *   **ç°è±¡**: `build_sparse_graph` ä»…ä¾èµ–é˜ˆå€¼åçš„ 6-é‚»åŸŸè¿æ¥ã€‚
    *   **é£é™©**: è‹¥ U-Net è¾“å‡ºæ–­è£‚ (Dice < 0.15)ï¼Œå›¾ä¼šåˆ†è£‚æˆæ— æ•°å­¤ç«‹å­å›¾ã€‚`auto_assign_seeds` ä»…åœ¨ Volume è¾¹ç•Œå’Œä¸­å¿ƒåˆ†é…ç§å­ã€‚å­¤ç«‹çš„ä¸­é—´ç¢ç‰‡å°†æ— æ³•æ¥æ”¶åˆ°æ­£ç¡®çš„è¾¹ç•Œæ¡ä»¶ï¼Œå¯¼è‡´æ±‚è§£å‡ºçš„ Winding Number ä¸º 0 æˆ–éšæœºå€¼ã€‚
    *   **å»ºè®®**: åœ¨ Graph æ„å»ºå‰å¼•å…¥å½¢æ€å­¦é—­è¿ç®— (Closing) æˆ–åœ¨ Solver ä¸­å¢åŠ è¿é€šåˆ†é‡åˆ†æã€‚

4.  **[MEDIUM] æ¨ç†èµ„æºä¸æ€§èƒ½**
    *   **åˆ†æ**: å• Chunk ($512^3$) æ¨ç†æ˜¾å­˜çº¦ 4GBï¼ŒRAM çº¦ 5GBï¼Œæ—¶é—´çº¦ 25sã€‚è™½ç„¶ä¸ä¼šç«‹å³ OOMï¼Œä½†è‹¥æ‰©å±•åˆ° $8000^3$ å…¨å›¾åˆ™å¿…æ­»æ— ç–‘ã€‚
    *   **å»ºè®®**: ä¿æŒåˆ†å— (Sliding Window) ç­–ç•¥ï¼Œå¹¶ä¸¥æ ¼ç›‘æ§é‡å åŒºåŸŸçš„å¤„ç†ã€‚

---

## ğŸ› ï¸ ä»£ç ä¿®æ­£æ–¹æ¡ˆ (Actionable Fixes)

### 1. ä¿®æ­£ `chimera_loss.py` (å¼•å…¥ Focal Loss & Weighted BCE)

**æ–‡ä»¶**: `20_src/20_model/chimera_loss.py`

```python
# ä¿®æ”¹ Class: ChimeraLoss

class ChimeraLoss(nn.Module):
    def __init__(
        self,
        lambda_normal: float = 1.0,
        lambda_bce: float = 1.0,
        dice_smooth: float = 1e-6,
        pos_weight: float = 100.0,  # æ–°å¢: æ­£æ ·æœ¬æƒé‡
    ):
        super().__init__()
        self.lambda_normal = lambda_normal
        self.lambda_bce = lambda_bce
        self.dice_loss = DiceLoss(smooth=dice_smooth)
        
        # æ ¸å¿ƒä¿®å¤: å¼•å…¥ pos_weight æƒ©ç½šèƒŒæ™¯é¢„æµ‹
        # pos_weight > 1 å¢åŠ  Recallï¼Œ< 1 å¢åŠ  Precision
        self.bce_loss = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight))
        
        self.normal_loss = NormalCosineLoss()

    def forward(self, seg_logits, pred_normals, targets):
        # ... (åŒå‰)
        # ç¡®ä¿ pos_weight åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        if self.bce_loss.pos_weight.device != seg_logits.device:
            self.bce_loss.pos_weight = self.bce_loss.pos_weight.to(seg_logits.device)
            
        bce_val = self.bce_loss(seg_logits, targets.float())
        # ...
```

### 2. ä¿®æ­£ `dual_unet.py` (ä¿æŠ¤ Z è½´åˆ†è¾¨ç‡)

**æ–‡ä»¶**: `20_src/20_model/dual_unet.py`

**åŸç†**: å°† `MaxPool3d(2)` æ”¹ä¸º `MaxPool3d(kernel_size=(1, 2, 2))`ã€‚è¿™æ · Z è½´ä¿æŒä¸å˜ï¼ŒXY è½´é™é‡‡æ ·ã€‚è¿™å¯¹äºåˆ‡ç‰‡æ•°æ®è‡³å…³é‡è¦ã€‚

```python
# ä¿®æ”¹ Class: DualHeadResUNet3D

def __init__(self, in_channels: int = 1, n_filters: int = 16):
    super().__init__()

    # ===== Encoder (å„å‘å¼‚æ€§ä¸‹é‡‡æ ·) =====
    self.enc1 = DoubleConv3D(in_channels, n_filters)
    # ç¬¬ä¸€å±‚å¯ä»¥åšå…¨å‘é™é‡‡æ · (64 -> 32)
    self.pool1 = nn.MaxPool3d(2)  

    self.enc2 = DoubleConv3D(n_filters, n_filters * 2)
    # ç¬¬äºŒå±‚å¼€å§‹ä¿æŠ¤ Z è½´ (32 -> 32)
    self.pool2 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))

    self.enc3 = DoubleConv3D(n_filters * 2, n_filters * 4)
    # ç¬¬ä¸‰å±‚ç»§ç»­ä¿æŠ¤ Z è½´ (32 -> 32)
    self.pool3 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))

    self.enc4 = DoubleConv3D(n_filters * 4, n_filters * 8)
    # ç¬¬å››å±‚ç»§ç»­ä¿æŠ¤ Z è½´ (32 -> 32)
    self.pool4 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))

    # ç»“æœ: Z è½´åªåœ¨ç¬¬ä¸€å±‚é™é‡‡æ ·äº†ä¸€æ¬¡ (64 -> 32)ï¼Œä¿ç•™äº†è¶³å¤Ÿçš„åšåº¦ä¿¡æ¯ã€‚
    # ç›¸åº”çš„ Decoder ä¸Šé‡‡æ ·å±‚ (ConvTranspose3d) ä¹Ÿå¿…é¡»ä¿®æ”¹ kernel/strideã€‚
```

---

## ğŸ”® æ¢¯åº¦åˆ†æç»“è®º

*   **å½“å‰æ¢¯åº¦**: ç”±äºæ­£æ ·æœ¬æå°‘ï¼Œ`L_BCE` çš„æ¢¯åº¦ä¸»è¦ç”±è´Ÿæ ·æœ¬è´¡çŒ®ã€‚è´Ÿæ ·æœ¬å‘Šè¯‰ç½‘ç»œï¼šâ€œé™ä½ logits å€¼ï¼â€ã€‚ç½‘ç»œç…§åšï¼Œå°†æ‰€æœ‰ logits æ¨å‘ -10ï¼Œå¯¼è‡´ Sigmoid è¾“å‡ºå…¨æ˜¯ 0ã€‚`L_Dice` åœ¨é¢„æµ‹å…¨ 0 æ—¶æ¢¯åº¦æ¶ˆå¤±æˆ–ä¸ç¨³å®šã€‚
*   **ä¿®æ­£åæ¢¯åº¦**: `pos_weight=100` å°†å¼ºåˆ¶ç½‘ç»œå…³æ³¨é‚£ 1% çš„æ­£æ ·æœ¬ã€‚æ­£æ ·æœ¬çš„æ¢¯åº¦å°†æ”¾å¤§ 100 å€ï¼Œå‘Šè¯‰ç½‘ç»œï¼šâ€œè¿™é‡Œå¿…é¡»æ˜¯ 1ï¼â€ã€‚è¿™å°†å¹³è¡¡è´Ÿæ ·æœ¬çš„å‹åˆ¶ï¼Œæ‰“ç ´è™šæ— ä¸»ä¹‰é™·é˜±ã€‚

**ä¸‹ä¸€æ­¥è¡ŒåŠ¨**:
æˆ‘å°†ç›´æ¥åº”ç”¨ä¸Šè¿°ä»£ç ä¿®æ”¹ã€‚

```

---
## File: __init__.py
```py
# 20_src: Hybrid Chimera MVP æ¨¡å—
# é˜¶æ®µä¸€: æ•°æ®å±‚ + å›¾æ„å»º
# é˜¶æ®µäºŒ: åŒå¤´ U-Net æ„ŸçŸ¥å±‚
# é˜¶æ®µä¸‰: Winding Number æ±‚è§£å™¨

```

---
## File: graph_builder.py
```py
"""
Vesuvius Challenge - ç¨€ç–å›¾æ„å»ºæ¨¡å— (MVP)

ä» U-Net è¾“å‡ºçš„æ¦‚ç‡å›¾å’Œæ³•çº¿å›¾æ„å»º voxel-level ç¨€ç–è¿æ¥å›¾ã€‚
å‚è€ƒ ThaumatoAnakalyptor instances_to_graph.py çš„æ ¸å¿ƒæ¦‚å¿µï¼Œçº¯ Python é‡å†™ã€‚

æ ¸å¿ƒé€»è¾‘ï¼š
1. é˜ˆå€¼åŒ–æ¦‚ç‡å›¾ï¼Œæå–æœ‰æ•ˆ voxel ä½œä¸ºèŠ‚ç‚¹
2. 6-é‚»åŸŸè¿æ¥ï¼Œè¾¹æƒé‡ = æ³•çº¿å‘é‡ç‚¹ç§¯ï¼ˆé«˜å¯¹é½ = å¼ºè¿æ¥ï¼‰
3. è¾“å‡º scipy.sparse.csr_matrix é‚»æ¥çŸ©é˜µ
"""

import numpy as np
from scipy import sparse
from typing import Tuple, Dict, Optional


def build_sparse_graph(
    prob_map: np.ndarray,
    normal_map: np.ndarray,
    threshold: float = 0.5,
    use_cupy: bool = False,
) -> Tuple[sparse.csr_matrix, np.ndarray, Dict[tuple, int]]:
    """
    ä»æ¦‚ç‡å›¾å’Œæ³•çº¿å›¾æ„å»ºç¨€ç–é‚»æ¥å›¾

    Args:
        prob_map: å½¢çŠ¶ (D, H, W)ï¼ŒU-Net è¾“å‡ºçš„æ¦‚ç‡å›¾ï¼Œå€¼åŸŸ [0, 1]
        normal_map: å½¢çŠ¶ (3, D, H, W)ï¼Œé¢„æµ‹çš„æ³•çº¿å›¾ï¼Œ(nx, ny, nz)
        threshold: æ¦‚ç‡é˜ˆå€¼ï¼Œé«˜äºæ­¤å€¼çš„ voxel æˆä¸ºèŠ‚ç‚¹ï¼Œé»˜è®¤ 0.5
        use_cupy: æ˜¯å¦ä½¿ç”¨ CuPy è¿›è¡Œ GPU åŠ é€Ÿï¼ˆé¢„ç•™æ¥å£ï¼‰ï¼Œé»˜è®¤ False

    Returns:
        adjacency: scipy.sparse.csr_matrixï¼Œç¨€ç–é‚»æ¥çŸ©é˜µï¼Œå½¢çŠ¶ (N, N)
        node_coords: np.ndarrayï¼Œå½¢çŠ¶ (N, 3)ï¼Œæ¯ä¸ªèŠ‚ç‚¹çš„ (d, h, w) åæ ‡
        node_index_map: dictï¼Œ(d, h, w) â†’ èŠ‚ç‚¹ç´¢å¼•çš„æ˜ å°„

    Raises:
        ValueError: è¾“å…¥å½¢çŠ¶ä¸åŒ¹é…æ—¶æŠ›å‡º
    """
    # --- è¾“å…¥æ ¡éªŒ ---
    if prob_map.ndim != 3:
        raise ValueError(f"prob_map å¿…é¡»æ˜¯ 3D æ•°ç»„ï¼Œå®é™…: {prob_map.ndim}D")
    if normal_map.ndim != 4 or normal_map.shape[0] != 3:
        raise ValueError(
            f"normal_map å¿…é¡»æ˜¯ (3, D, H, W) å½¢çŠ¶ï¼Œå®é™…: {normal_map.shape}"
        )
    if prob_map.shape != normal_map.shape[1:]:
        raise ValueError(
            f"prob_map {prob_map.shape} å’Œ normal_map {normal_map.shape[1:]} "
            f"ç©ºé—´å°ºå¯¸ä¸åŒ¹é…"
        )

    D, H, W = prob_map.shape

    # --- æ­¥éª¤ 1: é˜ˆå€¼åŒ–ï¼Œæå–æœ‰æ•ˆ voxel åæ ‡ ---
    mask = prob_map > threshold
    coords = np.argwhere(mask)  # (N, 3)ï¼Œæ¯è¡Œæ˜¯ (d, h, w)
    num_nodes = len(coords)

    if num_nodes == 0:
        # æ²¡æœ‰æœ‰æ•ˆèŠ‚ç‚¹ï¼Œè¿”å›ç©ºå›¾
        empty_adj = sparse.csr_matrix((0, 0), dtype=np.float32)
        return empty_adj, np.empty((0, 3), dtype=np.int64), {}

    print(f"[build_sparse_graph] æœ‰æ•ˆèŠ‚ç‚¹æ•°: {num_nodes} / {D*H*W} "
          f"(å æ¯” {num_nodes / (D*H*W) * 100:.1f}%)")

    # --- æ­¥éª¤ 2: å»ºç«‹åæ ‡ â†’ ç´¢å¼•æ˜ å°„ ---
    node_index_map: Dict[tuple, int] = {}
    for i, (d, h, w) in enumerate(coords):
        node_index_map[(int(d), int(h), int(w))] = i

    # --- æ­¥éª¤ 3: æ„å»ºè¾¹ï¼ˆ6-é‚»åŸŸï¼‰ ---
    # 6 ä¸ªé‚»åŸŸæ–¹å‘: Â±d, Â±h, Â±w
    neighbors_offsets = np.array([
        [-1, 0, 0], [1, 0, 0],   # d æ–¹å‘
        [0, -1, 0], [0, 1, 0],   # h æ–¹å‘
        [0, 0, -1], [0, 0, 1],   # w æ–¹å‘
    ], dtype=np.int64)

    # ä½¿ç”¨å‘é‡åŒ–æ“ä½œåŠ é€Ÿè¾¹æ„å»º
    row_indices = []
    col_indices = []
    weights = []

    # æå–æ¯ä¸ªèŠ‚ç‚¹çš„æ³•çº¿å‘é‡ (N, 3)
    node_normals = np.stack([
        normal_map[c, coords[:, 0], coords[:, 1], coords[:, 2]]
        for c in range(3)
    ], axis=1)  # (N, 3)

    # éå†æ¯ä¸ªé‚»åŸŸæ–¹å‘ï¼Œæ‰¹é‡å¤„ç†
    for offset in neighbors_offsets:
        # è®¡ç®—æ‰€æœ‰èŠ‚ç‚¹çš„é‚»å±…åæ ‡
        neighbor_coords = coords + offset  # (N, 3)

        # è¾¹ç•Œæ£€æŸ¥
        valid_mask = (
            (neighbor_coords[:, 0] >= 0) & (neighbor_coords[:, 0] < D) &
            (neighbor_coords[:, 1] >= 0) & (neighbor_coords[:, 1] < H) &
            (neighbor_coords[:, 2] >= 0) & (neighbor_coords[:, 2] < W)
        )

        # éå†æœ‰æ•ˆçš„é‚»å±…ï¼ˆéœ€è¦æŸ¥å­—å…¸ç¡®è®¤æ˜¯èŠ‚ç‚¹ï¼‰
        valid_indices = np.where(valid_mask)[0]

        for i in valid_indices:
            nb_key = tuple(neighbor_coords[i])
            if nb_key in node_index_map:
                j = node_index_map[nb_key]

                # è®¡ç®—è¾¹æƒé‡: ä¸¤ä¸ªèŠ‚ç‚¹æ³•çº¿çš„ç‚¹ç§¯
                dot = np.dot(node_normals[i], node_normals[j])

                # åªä¿ç•™æ­£å¯¹é½ï¼ˆæ³•çº¿æ–¹å‘ä¸€è‡´ = å±äºåŒä¸€è¡¨é¢ï¼‰
                weight = max(float(dot), 0.0)

                if weight > 0:
                    row_indices.append(i)
                    col_indices.append(j)
                    weights.append(weight)

    # --- æ­¥éª¤ 4: æ„å»ºç¨€ç–çŸ©é˜µ ---
    if len(row_indices) == 0:
        adjacency = sparse.csr_matrix(
            (num_nodes, num_nodes), dtype=np.float32
        )
    else:
        row_indices = np.array(row_indices, dtype=np.int64)
        col_indices = np.array(col_indices, dtype=np.int64)
        weights = np.array(weights, dtype=np.float32)

        adjacency = sparse.csr_matrix(
            (weights, (row_indices, col_indices)),
            shape=(num_nodes, num_nodes),
            dtype=np.float32,
        )

    print(f"[build_sparse_graph] è¾¹æ•°: {adjacency.nnz} "
          f"(å¹³å‡åº¦: {adjacency.nnz / max(num_nodes, 1):.2f})")

    return adjacency, coords, node_index_map


def build_graph_laplacian(adjacency: sparse.csr_matrix) -> sparse.csr_matrix:
    """
    ä»é‚»æ¥çŸ©é˜µæ„å»º Graph Laplacian: L = D - A

    Args:
        adjacency: ç¨€ç–é‚»æ¥çŸ©é˜µ (N, N)

    Returns:
        laplacian: ç¨€ç– Laplacian çŸ©é˜µ (N, N)
    """
    # åº¦çŸ©é˜µ: æ¯è¡Œæƒé‡ä¹‹å’Œ
    degree = np.array(adjacency.sum(axis=1)).flatten()
    D = sparse.diags(degree, format='csr')

    # Laplacian = D - A
    laplacian = D - adjacency

    return laplacian


if __name__ == "__main__":
    print("=== build_sparse_graph è‡ªæµ‹ ===")

    # åˆ›å»ºåˆæˆæ•°æ®: 8x8x8 ä½“ç§¯
    D, H, W = 8, 8, 8
    prob_map = np.zeros((D, H, W), dtype=np.float32)

    # ä¸­å¿ƒ 4x4x4 åŒºåŸŸè®¾ä¸ºé«˜æ¦‚ç‡
    prob_map[2:6, 2:6, 2:6] = 0.8

    # æ‰€æœ‰æ³•çº¿æŒ‡å‘ z æ–¹å‘ (å®Œç¾å¯¹é½)
    normal_map = np.zeros((3, D, H, W), dtype=np.float32)
    normal_map[2, :, :, :] = 1.0  # nz = 1.0

    # æ„å»ºå›¾
    adj, coords, idx_map = build_sparse_graph(prob_map, normal_map)

    print(f"èŠ‚ç‚¹æ•°: {len(coords)}")        # é¢„æœŸ: 4^3 = 64
    print(f"è¾¹æ•°: {adj.nnz}")              # é¢„æœŸ: æ¯ä¸ªå†…éƒ¨èŠ‚ç‚¹ 6 æ¡è¾¹
    print(f"é‚»æ¥çŸ©é˜µå½¢çŠ¶: {adj.shape}")

    assert len(coords) == 64, f"é¢„æœŸ 64 ä¸ªèŠ‚ç‚¹ï¼Œå®é™… {len(coords)}"
    assert adj.nnz > 0, "é‚»æ¥çŸ©é˜µåº”æœ‰éé›¶å…ƒç´ "

    # æµ‹è¯• Laplacian
    L = build_graph_laplacian(adj)
    print(f"Laplacian å½¢çŠ¶: {L.shape}")

    # Laplacian çš„æ¯è¡Œä¹‹å’Œåº”ä¸º 0
    row_sums = np.abs(np.array(L.sum(axis=1)).flatten())
    assert row_sums.max() < 1e-6, f"Laplacian è¡Œå’Œä¸ä¸ºé›¶: {row_sums.max()}"

    print("âœ“ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")

```

---
## File: preprocess.py
```py
"""
Vesuvius Challenge - æ•°æ®é¢„å¤„ç†è„šæœ¬

åŠŸèƒ½ï¼šå°† LZW å‹ç¼©çš„ TIF è½¬æ¢ä¸ºæœªå‹ç¼©çš„ NumPy æ ¼å¼ (.npy)ã€‚
ç›®çš„ï¼šå½»åº•è§£å†³è®­ç»ƒæ—¶çš„ IO ç“¶é¢ˆï¼Œæ”¯æŒ Memory-Mapped (mmap) é›¶æ‹·è´è¯»å–ã€‚
æ€§èƒ½æå‡ï¼šé¢„è®¡è®­ç»ƒ IO é€Ÿåº¦æå‡ 100 å€ã€‚
ç¡¬ç›˜å ç”¨ï¼šçº¦ 25GB (786 ä¸ª volumes)ã€‚

ç”¨æ³•:
    python 20_src/preprocess.py
"""

import os
import sys
from pathlib import Path
import numpy as np
import tifffile
from tqdm import tqdm
import multiprocessing

# é…ç½®
# åŸå§‹æ•°æ®ç›®å½•
SRC_IMG_DIR = Path("data/vesuvius-challenge-surface-detection/train_images")
SRC_LBL_DIR = Path("data/vesuvius-challenge-surface-detection/train_labels")

# è¾“å‡ºç›®å½•
DST_IMG_DIR = Path("data/vesuvius-challenge-surface-detection/train_images_npy")
DST_LBL_DIR = Path("data/vesuvius-challenge-surface-detection/train_labels_npy")


def convert_file(args):
    """
    å•ä¸ªæ–‡ä»¶è½¬æ¢ä»»åŠ¡
    """
    src_path, dst_path, is_label = args
    src_path = Path(src_path)
    dst_path = Path(dst_path)
    
    if dst_path.exists():
        return  # è·³è¿‡å·²å­˜åœ¨çš„

    try:
        # è¯»å– TIF
        volume = tifffile.imread(src_path)
        
        # ç¡®ä¿æ˜¯ 3D
        if volume.ndim == 2:
            volume = volume[np.newaxis, ...]
        
        # è½¬ä¸º uint8 (èŠ‚çœç©ºé—´ï¼Œè®­ç»ƒæ—¶å†è½¬ float32)
        # åŸå§‹æ•°æ®é€šå¸¸å°±æ˜¯ uint8ï¼Œè¿™é‡Œç¡®ä¿ç±»å‹ä¸€è‡´
        if volume.dtype != np.uint8:
            if volume.max() <= 1.0:
                volume = (volume * 255).astype(np.uint8)
            elif volume.max() <= 255:
                volume = volume.astype(np.uint8)
            # å¦‚æœæ˜¯ label ä¸” max > 1 (e.g. 255)ï¼Œä¹Ÿå¯ä»¥ä¿æŒ uint8
        
        # ä¿å­˜ä¸º .npy (æœªå‹ç¼©)
        np.save(dst_path, volume)
        
    except Exception as e:
        print(f"\nError converting {src_path}: {e}")


def main():
    print(f"{'='*50}")
    print(f"  ğŸš€ Vesuvius æ•°æ®é¢„å¤„ç† (TIF -> NPY)")
    print(f"  æºç›®å½•: {SRC_IMG_DIR}")
    print(f"  ç›®æ ‡ç›®å½•: {DST_IMG_DIR}")
    print(f"{'='*50}\n")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    DST_IMG_DIR.mkdir(parents=True, exist_ok=True)
    DST_LBL_DIR.mkdir(parents=True, exist_ok=True)
    
    tasks = []
    
    # æ‰«æ Image
    img_files = sorted(list(SRC_IMG_DIR.glob("*.tif")))
    for p in img_files:
        dst = DST_IMG_DIR / (p.stem + ".npy")
        tasks.append((str(p), str(dst), False))
        
    # æ‰«æ Label
    lbl_files = sorted(list(SRC_LBL_DIR.glob("*.tif")))
    for p in lbl_files:
        dst = DST_LBL_DIR / (p.stem + ".npy")
        tasks.append((str(p), str(dst), True))
        
    print(f"æ‰¾åˆ° {len(img_files)} ä¸ª image æ–‡ä»¶, {len(lbl_files)} ä¸ª label æ–‡ä»¶ã€‚")
    print(f"æ€»ä»»åŠ¡æ•°: {len(tasks)}")
    
    # å¹¶è¡Œå¤„ç† (æ ¹æ® CPU æ ¸æ•°)
    # Windows ä¸‹å¤šè¿›ç¨‹è¦æ³¨æ„ if __name__ == '__main__':
    num_workers = min(8, os.cpu_count() or 4)
    print(f"ä½¿ç”¨ {num_workers} ä¸ªè¿›ç¨‹å¹¶è¡Œè½¬æ¢...")
    
    with multiprocessing.Pool(processes=num_workers) as pool:
        list(tqdm(pool.imap_unordered(convert_file, tasks), total=len(tasks), unit="file"))
        
    print("\nâœ… è½¬æ¢å®Œæˆï¼")
    print(f"è¾“å‡ºå¤§å°æ£€æŸ¥: {DST_IMG_DIR}")


if __name__ == "__main__":
    # Windows å¿…é¡»
    multiprocessing.freeze_support()
    main()

```

---
## File: run_inference.py
```py
"""
Vesuvius Challenge - GPU æ¨ç†è„šæœ¬ v2

æ ¸å¿ƒæ”¹è¿›ï¼š
- Sliding Window åˆ†å—æ¨ç†ï¼šé¿å… 320Â³ ä½“ç§¯ç›´æ¥é€å…¥ GPU å¯¼è‡´ OOM
- å®æ—¶è¿›åº¦ç›‘æ§ï¼šGPU æ˜¾å­˜ã€å¤„ç†é€Ÿåº¦ã€ETA
- è§„èŒƒåŒ–è¾“å‡ºç›®å½•å‘½åï¼šchimera_run_{æ—¥æœŸ}_{æ¨¡å¼}

ç”¨æ³•:
    python 20_src/run_inference.py --max_chunks 5
    python 20_src/run_inference.py --checkpoint path/to/model.pth
"""

import os
import sys
import time
import argparse
import psutil
from pathlib import Path
from datetime import datetime, timedelta

import numpy as np
import torch
import torch.nn.functional as F
import tifffile

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨ sys.path ä¸­
PROJECT_ROOT = Path(__file__).resolve().parent.parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from importlib import import_module

model_mod = import_module("20_src.20_model.dual_unet")
DualHeadResUNet3D = model_mod.DualHeadResUNet3D


# ===== ç›‘æ§å·¥å…· =====

def get_gpu_stats():
    """è·å– GPU æ˜¾å­˜ä½¿ç”¨ä¿¡æ¯"""
    if not torch.cuda.is_available():
        return "CPU æ¨¡å¼"
    allocated = torch.cuda.memory_allocated() / 1024**3
    reserved = torch.cuda.memory_reserved() / 1024**3
    total = torch.cuda.get_device_properties(0).total_memory / 1024**3
    return f"GPU: {allocated:.1f}G/{total:.1f}G (reserved {reserved:.1f}G)"


def get_ram_stats():
    """è·å– RAM ä½¿ç”¨ä¿¡æ¯"""
    mem = psutil.virtual_memory()
    used_gb = mem.used / 1024**3
    total_gb = mem.total / 1024**3
    return f"RAM: {used_gb:.1f}G/{total_gb:.1f}G ({mem.percent}%)"


def format_eta(seconds):
    """æ ¼å¼åŒ–å‰©ä½™æ—¶é—´"""
    if seconds < 0:
        return "è®¡ç®—ä¸­..."
    td = timedelta(seconds=int(seconds))
    return str(td)


def print_progress(current, total, chunk_id, stage, extra=""):
    """æ‰“å°å®æ—¶è¿›åº¦"""
    pct = current / total * 100 if total > 0 else 0
    bar_len = 30
    filled = int(bar_len * current / total) if total > 0 else 0
    bar = "â–ˆ" * filled + "â–‘" * (bar_len - filled)

    timestamp = datetime.now().strftime("%H:%M:%S")
    line = f"[{timestamp}] [{bar}] {current}/{total} ({pct:.0f}%) | ID:{chunk_id} | {stage}"
    if extra:
        line += f" | {extra}"
    print(line, flush=True)


# ===== åˆ†å—æ¨ç†å¼•æ“ =====

def sliding_window_inference(
    model,
    volume: torch.Tensor,
    patch_size: tuple = (64, 128, 128),
    overlap: int = 8,
    device: torch.device = None,
):
    """
    Sliding Window åˆ†å—æ¨ç†

    å°†å¤§ä½“ç§¯åˆ‡æˆå° patchï¼Œé€ä¸ªé€å…¥ GPU æ¨ç†ï¼Œå†æ‹¼å›æ¥ã€‚
    é‡å åŒºåŸŸä½¿ç”¨å¹³å‡èåˆã€‚

    Args:
        model: DualHeadResUNet3D
        volume: (1, 1, D, H, W) å®Œæ•´è¾“å…¥ä½“ç§¯
        patch_size: æ¯ä¸ª patch çš„å¤§å° (pD, pH, pW)
        overlap: patch ä¹‹é—´çš„é‡å ä½“ç´ æ•°
        device: æ¨ç†è®¾å¤‡

    Returns:
        seg_prob: (D, H, W) åˆ†å‰²æ¦‚ç‡å›¾
        normal_map: (3, D, H, W) æ³•çº¿å›¾
    """
    _, _, D, H, W = volume.shape
    pD, pH, pW = patch_size
    stride_d = pD - overlap
    stride_h = pH - overlap
    stride_w = pW - overlap

    # è¾“å‡ºç´¯ç§¯å™¨
    seg_sum = torch.zeros(1, 1, D, H, W, dtype=torch.float32)
    normal_sum = torch.zeros(1, 3, D, H, W, dtype=torch.float32)
    count = torch.zeros(1, 1, D, H, W, dtype=torch.float32)

    # è®¡ç®—æ‰€æœ‰ patch çš„èµ·å§‹ä½ç½®
    d_starts = list(range(0, max(D - pD + 1, 1), stride_d))
    h_starts = list(range(0, max(H - pH + 1, 1), stride_h))
    w_starts = list(range(0, max(W - pW + 1, 1), stride_w))

    # ç¡®ä¿è¦†ç›–è¾¹ç•Œ
    if d_starts[-1] + pD < D:
        d_starts.append(D - pD)
    if h_starts[-1] + pH < H:
        h_starts.append(H - pH)
    if w_starts[-1] + pW < W:
        w_starts.append(W - pW)

    total_patches = len(d_starts) * len(h_starts) * len(w_starts)
    patch_idx = 0

    for d0 in d_starts:
        for h0 in h_starts:
            for w0 in w_starts:
                patch_idx += 1

                # æå– patch
                d1 = min(d0 + pD, D)
                h1 = min(h0 + pH, H)
                w1 = min(w0 + pW, W)

                patch = volume[:, :, d0:d1, h0:h1, w0:w1]

                # Pad å¦‚æœå°ºå¯¸ä¸å¤Ÿ
                actual_d, actual_h, actual_w = d1 - d0, h1 - h0, w1 - w0
                if actual_d < pD or actual_h < pH or actual_w < pW:
                    pad_d = pD - actual_d
                    pad_h = pH - actual_h
                    pad_w = pW - actual_w
                    patch = F.pad(patch, (0, pad_w, 0, pad_h, 0, pad_d))

                # GPU æ¨ç†
                patch_gpu = patch.to(device)
                seg_logits, normals = model(patch_gpu)
                seg_prob = torch.sigmoid(seg_logits)

                # è£å‰ªå›å®é™…å°ºå¯¸
                seg_prob = seg_prob[:, :, :actual_d, :actual_h, :actual_w].cpu()
                normals = normals[:, :, :actual_d, :actual_h, :actual_w].cpu()

                # ç´¯åŠ 
                seg_sum[:, :, d0:d1, h0:h1, w0:w1] += seg_prob
                normal_sum[:, :, d0:d1, h0:h1, w0:w1] += normals
                count[:, :, d0:d1, h0:h1, w0:w1] += 1.0

                # æ¸…ç† GPU æ˜¾å­˜
                del patch_gpu, seg_logits, seg_prob, normals
                if device.type == "cuda":
                    torch.cuda.empty_cache()

                # æ¯ 5 ä¸ª patch æ‰“å°ä¸€æ¬¡è¿›åº¦
                if patch_idx % 5 == 0 or patch_idx == total_patches:
                    print(f"    patch {patch_idx}/{total_patches} | {get_gpu_stats()}", flush=True)

    # å¹³å‡èåˆ
    count = count.clamp(min=1.0)
    seg_avg = (seg_sum / count).squeeze().numpy()       # (D, H, W)
    normal_avg = (normal_sum / count).squeeze(0).numpy() # (3, D, H, W)

    return seg_avg, normal_avg


# ===== ä¸»æ¨ç†å‡½æ•° =====

def run_inference(args):
    """ä¸»æ¨ç†æµç¨‹"""

    # è®¾å¤‡
    if args.device == "auto":
        dev = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    else:
        dev = torch.device(args.device)

    # è§„èŒƒåŒ–è¾“å‡ºç›®å½•å‘½å: chimera_run_{æ—¥æœŸ}_{æ¨¡å¼}
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    mode_tag = "gpu" if dev.type == "cuda" else "cpu"
    run_name = f"chimera_run_{timestamp}_{mode_tag}_nf{args.n_filters}"
    run_output_dir = Path(args.output_dir) / run_name
    run_output_dir.mkdir(parents=True, exist_ok=True)

    print(f"\n{'='*70}")
    print(f"  ğŸ”¬ Hybrid Chimera MVP - æ¨ç†")
    print(f"  è®¾å¤‡: {dev} | {get_gpu_stats()}")
    print(f"  {get_ram_stats()}")
    print(f"  Patch å¤§å°: {args.patch_size}")
    print(f"  è¾“å…¥: {args.input_dir}")
    print(f"  è¾“å‡º: {run_output_dir}")
    print(f"{'='*70}\n")

    # åŠ è½½æ¨¡å‹
    model = DualHeadResUNet3D(in_channels=1, n_filters=args.n_filters)
    if args.checkpoint and os.path.exists(args.checkpoint):
        state_dict = torch.load(args.checkpoint, map_location=dev, weights_only=True)
        if any(k.startswith("model.") for k in state_dict.keys()):
            state_dict = {k.replace("model.", ""): v for k, v in state_dict.items()}
        model.load_state_dict(state_dict, strict=False)
        print(f"[Model] å·²åŠ è½½æƒé‡: {args.checkpoint}")
    else:
        print("[Model] ä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡ï¼ˆMVP æ¼”ç¤ºæ¨¡å¼ï¼‰")

    model.to(dev)
    model.eval()
    params = sum(p.numel() for p in model.parameters())
    print(f"[Model] å‚æ•°é‡: {params:,} | {get_gpu_stats()}\n")

    # æ‰«æè¾“å…¥
    input_path = Path(args.input_dir)
    tif_files = sorted([
        f for f in input_path.iterdir()
        if f.suffix.lower() in ('.tif', '.tiff')
    ])
    if args.max_chunks:
        tif_files = tif_files[:args.max_chunks]

    total = len(tif_files)
    print(f"[Data] {total} ä¸ª .tif æ–‡ä»¶å¾…å¤„ç†\n")

    # æ¨ç†å¾ªç¯
    all_times = []
    normal_stats = []

    with torch.no_grad():
        for idx, tif_file in enumerate(tif_files):
            chunk_id = tif_file.stem
            print_progress(idx + 1, total, chunk_id, "å¼€å§‹åŠ è½½")

            t_start = time.time()

            # 1. åŠ è½½
            t0 = time.time()
            volume_raw = tifffile.imread(str(tif_file))
            vol_shape = volume_raw.shape
            volume = volume_raw.astype(np.float32)
            if volume.max() > 1.0:
                volume = volume / 255.0 if volume.max() <= 255.0 else volume / 65535.0
            volume = np.clip(volume, 0.0, 1.0)
            x = torch.from_numpy(volume).unsqueeze(0).unsqueeze(0)  # (1,1,D,H,W)
            t_load = time.time() - t0

            print(f"    å½¢çŠ¶: {vol_shape} | åŠ è½½: {t_load:.2f}s | {get_ram_stats()}", flush=True)

            # 2. Sliding Window æ¨ç†
            t0 = time.time()
            patch_size = tuple(args.patch_size)
            seg_prob, normal_map = sliding_window_inference(
                model, x, patch_size=patch_size,
                overlap=args.overlap, device=dev,
            )
            t_unet = time.time() - t0

            # 3. æ³•å‘é‡è´¨é‡è¯Šæ–­
            # è®¡ç®—æ³•çº¿æ¨¡é•¿ (åº”æ¥è¿‘ 1.0) å’Œæ–¹å‘ä¸€è‡´æ€§
            norm_magnitude = np.linalg.norm(normal_map, axis=0)  # (D,H,W)
            mask_region = seg_prob > 0.3  # åªåœ¨æœ‰æ„ä¹‰çš„åŒºåŸŸç»Ÿè®¡
            if mask_region.sum() > 0:
                avg_norm = norm_magnitude[mask_region].mean()
                std_norm = norm_magnitude[mask_region].std()
                # æ–¹å‘ä¸€è‡´æ€§: é‚»å±…æ³•çº¿ç‚¹ç§¯çš„å‡å€¼
                normal_stats.append({
                    "id": chunk_id,
                    "avg_norm_magnitude": float(avg_norm),
                    "std_norm_magnitude": float(std_norm),
                })
                norm_diag = f"æ³•çº¿æ¨¡é•¿: {avg_norm:.3f}Â±{std_norm:.3f}"
            else:
                norm_diag = "æ³•çº¿: æ— æœ‰æ•ˆåŒºåŸŸ"

            # 4. é˜ˆå€¼åŒ–ç”Ÿæˆ mask
            t0 = time.time()
            final_mask = (seg_prob > 0.5).astype(np.uint8)
            t_post = time.time() - t0

            t_total = time.time() - t_start
            all_times.append(t_total)

            # 5. ä¿å­˜
            output_filename = f"{chunk_id}_mask.tif"
            output_path = run_output_dir / output_filename
            tifffile.imwrite(str(output_path), final_mask)

            # è®¡ç®— ETA
            avg_time = sum(all_times) / len(all_times)
            eta = avg_time * (total - idx - 1)
            mask_pct = final_mask.sum() / final_mask.size * 100

            print(f"    U-Net: {t_unet:.1f}s | åå¤„ç†: {t_post:.3f}s | "
                  f"æ€»è®¡: {t_total:.1f}s", flush=True)
            print(f"    Mask: {mask_pct:.1f}% | {norm_diag}", flush=True)
            print(f"    {get_gpu_stats()} | {get_ram_stats()}", flush=True)
            print(f"    ETA: {format_eta(eta)} | å¹³å‡: {avg_time:.1f}s/chunk", flush=True)
            print(f"    â†’ {output_path.name}", flush=True)
            print("", flush=True)

            # æ¸…ç†
            del x, volume, volume_raw
            if dev.type == "cuda":
                torch.cuda.empty_cache()

    # ===== æœ€ç»ˆæŠ¥å‘Š =====
    total_time = sum(all_times)
    avg_time = total_time / max(len(all_times), 1)

    print(f"\n{'='*70}")
    print(f"  æ¨ç†å®Œæˆ!")
    print(f"  å¤„ç†: {len(all_times)} chunks")
    print(f"  æ€»è€—æ—¶: {total_time:.1f}s ({total_time/60:.1f} min)")
    print(f"  å¹³å‡: {avg_time:.1f}s/chunk")
    print(f"  è¾“å‡º: {run_output_dir}")

    # æ³•å‘é‡è´¨é‡è¯Šæ–­æ±‡æ€»
    if normal_stats:
        avg_mag = np.mean([s['avg_norm_magnitude'] for s in normal_stats])
        avg_std = np.mean([s['std_norm_magnitude'] for s in normal_stats])
        print(f"\n  ğŸ“ æ³•å‘é‡è¯Šæ–­:")
        print(f"    å¹³å‡æ¨¡é•¿: {avg_mag:.3f} (ç†æƒ³=1.0)")
        print(f"    æ¨¡é•¿æ ‡å‡†å·®: {avg_std:.3f} (è¶Šä½è¶Šå¥½)")
        if avg_mag < 0.5:
            print(f"    âš ï¸ æ³•çº¿æ–¹å‘æ‚ä¹±ï¼Œå»ºè®®åŠ å¼º L_Cosine æƒé‡ (å½“å‰ 0.1 â†’ 0.5)")

    # å†…å­˜è¯Šæ–­
    print(f"\n  ğŸ’¾ èµ„æºè¯Šæ–­:")
    print(f"    {get_ram_stats()}")
    print(f"    {get_gpu_stats()}")
    ram_gb = psutil.virtual_memory().used / 1024**3
    if ram_gb > 16:
        print(f"    âš ï¸ RAM ä½¿ç”¨è¶…è¿‡ 16GBï¼Œå»ºè®®åŠ å…¥ supervoxel é™é‡‡æ ·")

    # æ—¶é—´è¯Šæ–­
    print(f"\n  â±ï¸ æ€§èƒ½è¯Šæ–­:")
    print(f"    å• chunk å¹³å‡: {avg_time:.1f}s")
    if avg_time > 900:  # 15 åˆ†é’Ÿ
        print(f"    âš ï¸ å• chunk > 15 minï¼Œå¿…é¡»åˆ‡æ¢åˆ° CuPy GPU æ±‚è§£å™¨")
    else:
        print(f"    âœ“ å• chunk æ—¶é—´å¯æ¥å—")

    estimated_full = avg_time * 786 / 60
    print(f"    é¢„ä¼°å…¨é‡æ¨ç†: {estimated_full:.0f} min ({estimated_full/60:.1f} h)")
    print(f"{'='*70}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Hybrid Chimera - GPU æ¨ç† v2")
    parser.add_argument("--input_dir", type=str,
                        default="data/vesuvius-challenge-surface-detection/train_images")
    parser.add_argument("--output_dir", type=str, default="20_src/output")
    parser.add_argument("--checkpoint", type=str, default=None)
    parser.add_argument("--device", type=str, default="auto")
    parser.add_argument("--n_filters", type=int, default=16)
    parser.add_argument("--max_chunks", type=int, default=None)
    parser.add_argument("--patch_size", type=int, nargs=3, default=[64, 128, 128],
                        help="Sliding window patch å¤§å° (D H W)")
    parser.add_argument("--overlap", type=int, default=8,
                        help="Patch é‡å ä½“ç´ æ•°")

    args = parser.parse_args()
    run_inference(args)

```

---
## File: submission.py
```py
"""
Vesuvius Challenge - Hybrid Chimera MVP æ¨ç†æµæ°´çº¿ (submission.py)

ç«¯åˆ°ç«¯æ¨ç†æµç¨‹ï¼š
1. åŠ è½½æµ‹è¯• 3D TIF Chunk
2. è¿è¡Œ DualHead U-Net â†’ æ¦‚ç‡å›¾ + æ³•çº¿å›¾
3. build_sparse_graph â†’ ç¨€ç–é‚»æ¥å›¾
4. solve_winding_number â†’ Winding Number åœº
5. cut_mesh â†’ Winding Mask
6. Porosity Injection: Final = Winding_Mask & (Prob > 0.4)
7. è¾“å‡ºæœ€ç»ˆ Binary Mask

åŒ…å«æ€§èƒ½è®¡æ—¶ï¼Œç¡®ä¿å• chunk < 10 åˆ†é’Ÿã€‚
"""

import os
import sys
import time
import argparse
from pathlib import Path
from typing import Optional

import numpy as np
import torch
import tifffile

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨ sys.path ä¸­
PROJECT_ROOT = Path(__file__).resolve().parent.parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

# ä½¿ç”¨ importlib å¯¼å…¥æ•°å­—å¼€å¤´çš„æ¨¡å—
from importlib import import_module

# é˜¶æ®µä¸€: æ•°æ®åŠ è½½ + å›¾æ„å»º
dataset_mod = import_module("20_src.20_data.dataset")
graph_mod = import_module("20_src.graph_builder")

# é˜¶æ®µäºŒ: åŒå¤´ U-Net
model_mod = import_module("20_src.20_model.dual_unet")

# é˜¶æ®µä¸‰: Winding Number æ±‚è§£å™¨
solver_mod = import_module("20_src.winding_solver")

TifChunkDataset = dataset_mod.TifChunkDataset
DualHeadResUNet3D = model_mod.DualHeadResUNet3D
build_sparse_graph = graph_mod.build_sparse_graph
solve_winding_number = solver_mod.solve_winding_number
cut_mesh = solver_mod.cut_mesh
auto_assign_seeds = solver_mod.auto_assign_seeds


class HybridChimeraPipeline:
    """
    Hybrid Chimera MVP æ¨ç†æµæ°´çº¿

    å°† DualHead U-Net çš„ç¥ç»æ„ŸçŸ¥è¾“å‡º
    ä¸ Winding Number å‡ ä½•æ±‚è§£å™¨çš„é€»è¾‘æ¨ç†ç»“åˆï¼Œ
    é€šè¿‡ Porosity Injection æ¢å¤æ‹“æ‰‘ç»†èŠ‚ã€‚
    """

    def __init__(
        self,
        checkpoint_path: Optional[str] = None,
        device: str = "auto",
        prob_threshold: float = 0.5,
        porosity_threshold: float = 0.4,
        winding_threshold: float = 0.5,
        use_cupy: bool = False,
        n_filters: int = 16,
    ):
        """
        Args:
            checkpoint_path: æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆ.pthï¼‰ï¼ŒNone åˆ™ä½¿ç”¨éšæœºæƒé‡
            device: æ¨ç†è®¾å¤‡ï¼Œ"auto" è‡ªåŠ¨é€‰æ‹©
            prob_threshold: å›¾æ„å»ºæ—¶çš„æ¦‚ç‡é˜ˆå€¼
            porosity_threshold: Porosity Injection çš„æ¦‚ç‡é˜ˆå€¼
            winding_threshold: Winding Number é˜ˆå€¼åŒ–
            use_cupy: æ˜¯å¦ä½¿ç”¨ CuPy GPU åŠ é€Ÿæ±‚è§£å™¨
            n_filters: æ¨¡å‹åŸºç¡€é€šé“æ•°
        """
        # è®¾å¤‡é€‰æ‹©
        if device == "auto":
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.device = torch.device(device)

        print(f"[Pipeline] è®¾å¤‡: {self.device}")

        self.prob_threshold = prob_threshold
        self.porosity_threshold = porosity_threshold
        self.winding_threshold = winding_threshold
        self.use_cupy = use_cupy

        # åŠ è½½æ¨¡å‹
        self.model = DualHeadResUNet3D(in_channels=1, n_filters=n_filters)
        if checkpoint_path and os.path.exists(checkpoint_path):
            state_dict = torch.load(checkpoint_path, map_location=self.device)
            # å…¼å®¹å¸¦ "model." å‰ç¼€çš„ checkpoint
            if any(k.startswith("model.") for k in state_dict.keys()):
                state_dict = {k.replace("model.", ""): v for k, v in state_dict.items()}
            self.model.load_state_dict(state_dict, strict=False)
            print(f"[Pipeline] å·²åŠ è½½æƒé‡: {checkpoint_path}")
        else:
            print("[Pipeline] ä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡ï¼ˆæœªæä¾› checkpointï¼‰")

        self.model.to(self.device)
        self.model.eval()

    @torch.no_grad()
    def _run_unet(self, volume: torch.Tensor):
        """
        æ­¥éª¤ 1-2: è¿è¡Œ DualHead U-Net

        Args:
            volume: (1, 1, D, H, W) è¾“å…¥ä½“ç§¯

        Returns:
            prob_map: (D, H, W) numpyï¼Œæ¦‚ç‡å›¾
            normal_map: (3, D, H, W) numpyï¼Œæ³•çº¿å›¾
        """
        x = volume.to(self.device)
        seg_logits, normals = self.model(x)

        # Sigmoid â†’ æ¦‚ç‡å›¾
        prob_map = torch.sigmoid(seg_logits).squeeze().cpu().numpy()  # (D, H, W)

        # æ³•çº¿å·²ç»æ˜¯ Tanh å½’ä¸€åŒ–åçš„ç»“æœ
        normal_map = normals.squeeze(0).cpu().numpy()  # (3, D, H, W)

        return prob_map, normal_map

    def _run_graph_solver(self, prob_map, normal_map):
        """
        æ­¥éª¤ 3-5: å›¾æ„å»º â†’ Winding Number æ±‚è§£ â†’ é˜ˆå€¼åŒ–

        Returns:
            winding_mask: (D, H, W) numpyï¼Œbinary mask
        """
        D, H, W = prob_map.shape

        # æ­¥éª¤ 3: æ„å»ºç¨€ç–å›¾
        adjacency, node_coords, node_index_map = build_sparse_graph(
            prob_map, normal_map, threshold=self.prob_threshold
        )

        if adjacency.shape[0] == 0:
            print("[Pipeline] è­¦å‘Š: æ— æœ‰æ•ˆèŠ‚ç‚¹ï¼Œè¿”å›ç©º mask")
            return np.zeros((D, H, W), dtype=np.float32)

        # æ­¥éª¤ 4: è‡ªåŠ¨åˆ†é…ç§å­ + æ±‚è§£
        seeds = auto_assign_seeds(node_coords, (D, H, W))

        if len(seeds) == 0:
            print("[Pipeline] è­¦å‘Š: æ— ç§å­èŠ‚ç‚¹ï¼Œå›é€€åˆ°æ¦‚ç‡é˜ˆå€¼åŒ–")
            return (prob_map > self.prob_threshold).astype(np.float32)

        winding_field = solve_winding_number(
            adjacency, seeds, use_cupy=self.use_cupy
        )

        # æ­¥éª¤ 5: é˜ˆå€¼åŒ–
        winding_mask = cut_mesh(
            winding_field, node_coords, (D, H, W),
            threshold=self.winding_threshold
        )

        return winding_mask

    def _porosity_injection(self, winding_mask, prob_map):
        """
        æ­¥éª¤ 6: Porosity Injection

        æ¢å¤ Winding Mask å¯èƒ½é—æ¼çš„å¾®å°å­”æ´å’Œè–„ç»“æ„ã€‚
        Final_Mask = Winding_Mask & (Prob_Map > porosity_threshold)

        åœ¨ Winding Mask çš„åŸºç¡€ä¸Šï¼Œç”¨æ›´å®½æ¾çš„æ¦‚ç‡é˜ˆå€¼
        è¡¥å›è¢«å‡ ä½•æ±‚è§£å™¨å¹³æ»‘æ‰çš„æ‹“æ‰‘ç»†èŠ‚ï¼ˆå¯¹ TopoScore è‡³å…³é‡è¦ï¼‰ã€‚
        """
        prob_mask = (prob_map > self.porosity_threshold).astype(np.float32)

        # äº¤é›†: ä¿ç•™ Winding è®¤ä¸ºçš„"å†…éƒ¨" ä¸” æ¦‚ç‡æ”¯æŒçš„åŒºåŸŸ
        # å¹¶é›†è¡¥å……: åœ¨ Winding å¤–ä½†æ¦‚ç‡é«˜çš„åŒºåŸŸä¹Ÿä¿ç•™ï¼ˆæ¢å¤å­”æ´ï¼‰
        final_mask = np.maximum(winding_mask, prob_mask)

        # æ›´ä¿å®ˆçš„ç‰ˆæœ¬ï¼ˆçº¯äº¤é›†ï¼‰ï¼š
        # final_mask = winding_mask * prob_mask

        winding_only = (winding_mask > 0).sum()
        prob_only = (prob_mask > 0).sum()
        final_count = (final_mask > 0).sum()

        print(f"[Porosity] Winding: {winding_only}, "
              f"Prob(>{self.porosity_threshold}): {prob_only}, "
              f"Final: {final_count}")

        return final_mask

    def process_chunk(self, volume: torch.Tensor):
        """
        å¤„ç†å•ä¸ª chunk çš„å®Œæ•´æ¨ç†æµç¨‹

        Args:
            volume: (1, 1, D, H, W) æˆ– (1, D, H, W) è¾“å…¥ä½“ç§¯

        Returns:
            final_mask: (D, H, W) numpyï¼Œæœ€ç»ˆ binary mask
            timings: dictï¼Œå„æ­¥éª¤è€—æ—¶
        """
        # ç¡®ä¿å½¢çŠ¶æ­£ç¡®
        if volume.dim() == 4:
            volume = volume.unsqueeze(0)  # (1, D, H, W) â†’ (1, 1, D, H, W)

        timings = {}
        total_start = time.time()

        # æ­¥éª¤ 1-2: U-Net æ¨ç†
        t0 = time.time()
        prob_map, normal_map = self._run_unet(volume)
        timings["unet_inference"] = time.time() - t0
        print(f"[Timer] U-Net æ¨ç†: {timings['unet_inference']:.2f}s")

        # æ­¥éª¤ 3-5: å›¾æ„å»º + Winding Number æ±‚è§£
        t0 = time.time()
        winding_mask = self._run_graph_solver(prob_map, normal_map)
        timings["graph_solver"] = time.time() - t0
        print(f"[Timer] å›¾+æ±‚è§£: {timings['graph_solver']:.2f}s")

        # æ­¥éª¤ 6: Porosity Injection
        t0 = time.time()
        final_mask = self._porosity_injection(winding_mask, prob_map)
        timings["porosity"] = time.time() - t0
        print(f"[Timer] Porosity: {timings['porosity']:.4f}s")

        timings["total"] = time.time() - total_start
        print(f"[Timer] æ€»è€—æ—¶: {timings['total']:.2f}s")

        # æ€§èƒ½æ£€æŸ¥: < 10 åˆ†é’Ÿ
        if timings["total"] > 600:
            print(f"âš ï¸ è­¦å‘Š: å• chunk è€—æ—¶ {timings['total']:.0f}s > 600sï¼Œ"
                  f"å¯èƒ½è¶…æ—¶ï¼")

        return final_mask, timings

    def process_directory(
        self,
        input_dir: str,
        output_dir: str,
    ):
        """
        æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰ .tif chunk

        Args:
            input_dir: è¾“å…¥ .tif æ–‡ä»¶ç›®å½•
            output_dir: è¾“å‡º mask ä¿å­˜ç›®å½•
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        dataset = TifChunkDataset(input_dir, normalize=True)
        total_chunks = len(dataset)
        all_timings = []

        print(f"\n{'='*60}")
        print(f"  Hybrid Chimera MVP - æ‰¹é‡æ¨ç†")
        print(f"  Chunks: {total_chunks}")
        print(f"  Device: {self.device}")
        print(f"{'='*60}\n")

        for i in range(total_chunks):
            print(f"\n--- Chunk {i+1}/{total_chunks}: "
                  f"{dataset.get_file_path(i)} ---")

            volume = dataset[i]  # (1, D, H, W)
            mask, timings = self.process_chunk(volume)
            all_timings.append(timings)

            # ä¿å­˜ç»“æœ
            input_name = Path(dataset.get_file_path(i)).stem
            output_file = output_path / f"{input_name}_mask.tif"
            tifffile.imwrite(str(output_file), mask.astype(np.uint8))
            print(f"[Save] â†’ {output_file}")

        # æ€»ç»“
        total_time = sum(t["total"] for t in all_timings)
        avg_time = total_time / max(len(all_timings), 1)

        print(f"\n{'='*60}")
        print(f"  æ¨ç†å®Œæˆ!")
        print(f"  æ€»è€—æ—¶: {total_time:.1f}s ({total_time/60:.1f} åˆ†é’Ÿ)")
        print(f"  å¹³å‡æ¯ chunk: {avg_time:.1f}s")
        print(f"  é¢„è®¡å…¨é‡æ¨ç† (å‡è®¾ 50 chunks): {avg_time * 50 / 60:.1f} åˆ†é’Ÿ")
        print(f"  9 å°æ—¶é™åˆ¶å†…å¯å¤„ç†: {int(9 * 3600 / max(avg_time, 0.1))} chunks")
        print(f"{'='*60}")


def main():
    parser = argparse.ArgumentParser(
        description="Hybrid Chimera MVP - Vesuvius æ¨ç†æµæ°´çº¿"
    )
    parser.add_argument(
        "--input_dir", type=str, required=True,
        help="è¾“å…¥ .tif æ–‡ä»¶ç›®å½•"
    )
    parser.add_argument(
        "--output_dir", type=str, default="20_src/20_outputs",
        help="è¾“å‡ºç›®å½•"
    )
    parser.add_argument(
        "--checkpoint", type=str, default=None,
        help="æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„ (.pth)"
    )
    parser.add_argument(
        "--device", type=str, default="auto",
        choices=["auto", "cuda", "cpu"],
        help="æ¨ç†è®¾å¤‡"
    )
    parser.add_argument(
        "--prob_threshold", type=float, default=0.5,
        help="å›¾æ„å»ºæ¦‚ç‡é˜ˆå€¼"
    )
    parser.add_argument(
        "--porosity_threshold", type=float, default=0.4,
        help="Porosity Injection æ¦‚ç‡é˜ˆå€¼"
    )
    parser.add_argument(
        "--winding_threshold", type=float, default=0.5,
        help="Winding Number é˜ˆå€¼"
    )
    parser.add_argument(
        "--use_cupy", action="store_true",
        help="ä½¿ç”¨ CuPy GPU åŠ é€Ÿæ±‚è§£å™¨"
    )
    parser.add_argument(
        "--n_filters", type=int, default=16,
        help="æ¨¡å‹åŸºç¡€é€šé“æ•°"
    )

    args = parser.parse_args()

    pipeline = HybridChimeraPipeline(
        checkpoint_path=args.checkpoint,
        device=args.device,
        prob_threshold=args.prob_threshold,
        porosity_threshold=args.porosity_threshold,
        winding_threshold=args.winding_threshold,
        use_cupy=args.use_cupy,
        n_filters=args.n_filters,
    )

    pipeline.process_directory(args.input_dir, args.output_dir)


if __name__ == "__main__":
    main()

```

---
## File: train.py
```py
"""
Vesuvius Challenge - Hybrid Chimera è®­ç»ƒå¼•æ“ (Phase 5)

Patch-based 3D è®­ç»ƒå¾ªç¯ï¼Œæ”¯æŒï¼š
- AMP æ··åˆç²¾åº¦ (FP16)
- Random Crop 3D + æ•°æ®å¢å¼º
- ChimeraLoss (Dice + Normal Cosine)
- tqdm è¿›åº¦æ¡
- æ¯ epoch å¯è§†åŒ–è¾“å‡º (PNG å¯¹æ¯”å›¾ + TIF mask)
- éªŒè¯ Dice ç›‘æ§ + Best Model ä¿å­˜

ç”¨æ³•:
    # å¿«é€Ÿæµ‹è¯• (5 ä¸ª chunk, 2 ä¸ª epoch)
    python 20_src/train.py --max_chunks 5 --epochs 2

    # å®Œæ•´è®­ç»ƒ
    python 20_src/train.py --epochs 50 --batch_size 4 --lr 1e-3

    # ä» checkpoint æ¢å¤
    python 20_src/train.py --resume 20_src/output/best_model.pth --epochs 50
"""

import os
import sys
import time
import json
import argparse
from pathlib import Path
from datetime import datetime, timedelta

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, random_split
from tqdm import tqdm
import tifffile

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨ sys.path ä¸­
PROJECT_ROOT = Path(__file__).resolve().parent.parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from importlib import import_module

# æ¨¡å‹
model_mod = import_module("20_src.20_model.dual_unet")
DualHeadResUNet3D = model_mod.DualHeadResUNet3D

# æŸå¤±å‡½æ•°
loss_mod = import_module("20_src.20_model.chimera_loss")
ChimeraLoss = loss_mod.ChimeraLoss

# æ•°æ®é›†
dataset_mod = import_module("20_src.20_data.dataset")
VesuviusTrainDataset = dataset_mod.VesuviusTrainDataset

# å˜æ¢
transforms_mod = import_module("20_src.20_data.transforms")
RandomCrop3D = transforms_mod.RandomCrop3D
RandomFlipRotate3D = transforms_mod.RandomFlipRotate3D
Compose3D = transforms_mod.Compose3D


# ===== å·¥å…·å‡½æ•° =====

def get_gpu_stats():
    """è·å– GPU æ˜¾å­˜ä½¿ç”¨ä¿¡æ¯"""
    if not torch.cuda.is_available():
        return "CPU"
    allocated = torch.cuda.memory_allocated() / 1024**3
    reserved = torch.cuda.memory_reserved() / 1024**3
    total = torch.cuda.get_device_properties(0).total_memory / 1024**3
    return f"GPU:{reserved:.1f}G/{total:.1f}G"


def compute_dice(pred_logits, targets, threshold=0.5):
    """è®¡ç®— Dice ç³»æ•°ï¼ˆè¯„ä¼°æŒ‡æ ‡ï¼‰"""
    pred = (torch.sigmoid(pred_logits) > threshold).float()
    smooth = 1e-6
    intersection = (pred * targets).sum()
    dice = (2.0 * intersection + smooth) / (pred.sum() + targets.sum() + smooth)
    return dice.item()


def format_time(seconds):
    """æ ¼å¼åŒ–æ—¶é—´"""
    td = timedelta(seconds=int(seconds))
    return str(td)


# ===== å¯è§†åŒ–å·¥å…· =====

def save_epoch_visualization(
    model, val_loader, device, run_dir, epoch, criterion
):
    """
    æ¯ä¸ª epoch ç»“æŸåä¿å­˜å¯è§†åŒ–å¯¹æ¯”ï¼š
    1. PNG å¯¹æ¯”å›¾ï¼šä¸­é—´ slice çš„ image / GT / prediction ä¸‰åˆ—å¯¹æ¯”
    2. TIF maskï¼šé¢„æµ‹ç»“æœ 3D volume
    """
    model.eval()

    # ä»éªŒè¯é›†å¯»æ‰¾ä¸€ä¸ªåŒ…å«æ­£æ ·æœ¬çš„ batch è¿›è¡Œå¯è§†åŒ–
    target_images = None
    target_labels = None
    
    try:
        # å°è¯•éå†éªŒè¯é›†å¯»æ‰¾æœ‰å¢¨æ°´çš„ patch
        for images, labels in val_loader:
            if labels.sum() > 0:
                target_images = images
                target_labels = labels
                break
        
        # å¦‚æœæ²¡æ‰¾åˆ°ï¼ˆæå…¶ç½•è§ï¼‰ï¼Œå°±é€€å›åˆ°ç¬¬ä¸€ä¸ª batch
        if target_images is None:
            target_images, target_labels = next(iter(val_loader))
            
    except StopIteration:
        return

    images = target_images.to(device)
    labels = target_labels.to(device)

    with torch.no_grad():
        with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):
            seg_logits, normals = model(images)
    
    # å–ç¬¬ä¸€ä¸ªæ ·æœ¬
    pred_prob = torch.sigmoid(seg_logits[0, 0]).cpu().numpy()    # (D, H, W)
    pred_mask = (pred_prob > 0.5).astype(np.uint8)               # äºŒå€¼ mask
    gt_mask = labels[0, 0].cpu().numpy()                          # (D, H, W)
    img_vol = images[0, 0].cpu().numpy()                          # (D, H, W)

    D, H, W = img_vol.shape

    # === 1. ä¿å­˜ TIF mask ===
    tif_dir = run_dir / "epoch_masks"
    tif_dir.mkdir(exist_ok=True)
    tif_path = tif_dir / f"epoch{epoch+1:03d}_pred_mask.tif"
    tifffile.imwrite(str(tif_path), pred_mask)

    # === 2. ä¿å­˜ PNG å¯¹æ¯”å›¾ ===
    try:
        import matplotlib
        matplotlib.use('Agg')  # éäº¤äº’å¼åç«¯
        import matplotlib.pyplot as plt

        vis_dir = run_dir / "epoch_vis"
        vis_dir.mkdir(exist_ok=True)

        # å– 3 ä¸ªæ­£äº¤ sliceï¼ˆä¸­é—´ä½ç½®ï¼‰
        slices = {
            'Axial (z-mid)': (img_vol[D//2], gt_mask[D//2], pred_prob[D//2], pred_mask[D//2]),
            'Coronal (y-mid)': (img_vol[:, H//2], gt_mask[:, H//2], pred_prob[:, H//2], pred_mask[:, H//2]),
            'Sagittal (x-mid)': (img_vol[:, :, W//2], gt_mask[:, :, W//2], pred_prob[:, :, W//2], pred_mask[:, :, W//2]),
        }

        fig, axes = plt.subplots(3, 4, figsize=(16, 12))
        fig.suptitle(f'Epoch {epoch+1} | Dice: {compute_dice(seg_logits[0:1], labels[0:1]):.4f}',
                     fontsize=16, fontweight='bold')

        for row_idx, (plane_name, (img_s, gt_s, prob_s, mask_s)) in enumerate(slices.items()):
            # åˆ— 1: Input CT
            axes[row_idx, 0].imshow(img_s, cmap='gray', vmin=0, vmax=1)
            axes[row_idx, 0].set_title(f'{plane_name}\nInput CT')
            axes[row_idx, 0].axis('off')

            # åˆ— 2: Ground Truth
            axes[row_idx, 1].imshow(gt_s, cmap='Reds', vmin=0, vmax=1, alpha=0.8)
            axes[row_idx, 1].set_title('Ground Truth')
            axes[row_idx, 1].axis('off')

            # åˆ— 3: Prediction (æ¦‚ç‡å›¾)
            axes[row_idx, 2].imshow(prob_s, cmap='hot', vmin=0, vmax=1)
            axes[row_idx, 2].set_title('Pred Prob')
            axes[row_idx, 2].axis('off')

            # åˆ— 4: Overlay (CT + Prediction å åŠ )
            axes[row_idx, 3].imshow(img_s, cmap='gray', vmin=0, vmax=1)
            axes[row_idx, 3].imshow(mask_s, cmap='Reds', alpha=0.4)
            axes[row_idx, 3].set_title('Overlay')
            axes[row_idx, 3].axis('off')

        plt.tight_layout()
        png_path = vis_dir / f"epoch{epoch+1:03d}_comparison.png"
        plt.savefig(str(png_path), dpi=120, bbox_inches='tight')
        plt.close(fig)

        print(f"  ğŸ“¸ 2D å¯¹æ¯”: {png_path.name} | ğŸ—‚ï¸ Mask: {tif_path.name}")

    except ImportError:
        print(f"  ğŸ—‚ï¸ Mask TIF: {tif_path.name} (matplotlib ä¸å¯ç”¨ï¼Œè·³è¿‡ PNG)")

    # === 3. 3D Volume Rendering (PyVista offscreen) ===
    try:
        import pyvista as pv
        import matplotlib.colors as mcolors

        pv.OFF_SCREEN = True
        vis_dir = run_dir / "epoch_vis"
        vis_dir.mkdir(exist_ok=True)

        p = pv.Plotter(shape=(1, 2), window_size=(1200, 600), off_screen=True)

        # å·¦: GT mask (ç»¿è‰²)
        p.subplot(0, 0)
        p.add_text(f"GT Mask (Epoch {epoch+1})", font_size=10)
        if gt_mask.sum() > 0:
            gt_grid = pv.wrap(gt_mask.astype(np.float32))
            gt_cmap = mcolors.LinearSegmentedColormap.from_list("gt", ["black", "lime"])
            p.add_volume(gt_grid, cmap=gt_cmap,
                         opacity=[0, 0.0, 0.1, 0.0, 0.9, 0.5, 1.0, 0.5],
                         blending="composite", show_scalar_bar=False)
        p.add_bounding_box()

        # å³: Prediction mask (çº¢è‰²)
        p.subplot(0, 1)
        p.add_text(f"Pred Mask (Epoch {epoch+1})", font_size=10)
        if pred_mask.sum() > 0:
            pred_grid = pv.wrap(pred_mask.astype(np.float32))
            pred_cmap = mcolors.LinearSegmentedColormap.from_list("pred", ["black", "red"])
            p.add_volume(pred_grid, cmap=pred_cmap,
                         opacity=[0, 0.0, 0.1, 0.0, 0.9, 0.5, 1.0, 0.5],
                         blending="composite", show_scalar_bar=False)
        p.add_bounding_box()

        p.link_views()

        png_3d_path = vis_dir / f"epoch{epoch+1:03d}_3d_comparison.png"
        p.screenshot(str(png_3d_path))
        p.close()

        print(f"  ğŸ§Š 3D å¯¹æ¯”: {png_3d_path.name}")

    except Exception as e:
        print(f"  âš ï¸ 3D æ¸²æŸ“è·³è¿‡: {e}")



# ===== è®­ç»ƒå¾ªç¯ =====

def train_one_epoch(
    model, dataloader, criterion, optimizer, scaler, device, epoch, total_epochs
):
    """è®­ç»ƒä¸€ä¸ª epochï¼ˆå¸¦ tqdm è¿›åº¦æ¡ï¼‰"""
    model.train()

    total_loss = 0.0
    total_dice_loss = 0.0
    total_bce_loss = 0.0
    total_normal_loss = 0.0
    total_dice_score = 0.0
    num_batches = 0

    pbar = tqdm(
        dataloader,
        desc=f"Train E{epoch+1}/{total_epochs}",
        ncols=120,
        leave=True,
    )

    for images, labels in pbar:
        images = images.to(device, non_blocking=True)  # (B, 1, D, H, W)
        labels = labels.to(device, non_blocking=True)  # (B, 1, D, H, W)

        optimizer.zero_grad(set_to_none=True)

        # AMP å‰å‘ä¼ æ’­
        with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):
            seg_logits, normals = model(images)
            loss_total, loss_dice, loss_bce, loss_normal = criterion(seg_logits, normals, labels)

        # AMP åå‘ä¼ æ’­
        if device.type == 'cuda':
            scaler.scale(loss_total).backward()
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            scaler.step(optimizer)
            scaler.update()
        else:
            loss_total.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

        # ç»Ÿè®¡
        dice_score = compute_dice(seg_logits.detach(), labels)
        total_loss += loss_total.item()
        total_dice_loss += loss_dice.item()
        total_bce_loss += loss_bce.item()
        total_normal_loss += loss_normal.item()
        total_dice_score += dice_score
        num_batches += 1

        # Debug "Playing Dead"
        if num_batches % 50 == 0:
            pred_sum = (torch.sigmoid(seg_logits) > 0.5).float().sum()
            target_sum = labels.sum()
            print(f"\n[DEBUG] Batch {num_batches}: Pred_Pixels={pred_sum.item()}, GT_Pixels={target_sum.item()}")

        # æ›´æ–° tqdm
        avg_loss = total_loss / num_batches
        avg_dice = total_dice_score / num_batches
        pbar.set_postfix({
            'loss': f'{avg_loss:.2f}',
            'bce': f'{total_bce_loss/num_batches:.2f}',
            'dice': f'{avg_dice:.2f}',
            'norm': f'{total_normal_loss/num_batches:.2f}',
            'gpu': get_gpu_stats(),
        })

    pbar.close()

    # epoch ç»Ÿè®¡
    avg_loss = total_loss / max(num_batches, 1)
    avg_dice_loss = total_dice_loss / max(num_batches, 1)
    avg_bce_loss = total_bce_loss / max(num_batches, 1)
    avg_normal_loss = total_normal_loss / max(num_batches, 1)
    avg_dice_score = total_dice_score / max(num_batches, 1)

    return {
        "loss": avg_loss,
        "dice_loss": avg_dice_loss,
        "bce_loss": avg_bce_loss,
        "normal_loss": avg_normal_loss,
        "dice_score": avg_dice_score,
    }


@torch.no_grad()
def validate(model, dataloader, criterion, device, epoch, total_epochs):
    """éªŒè¯ä¸€ä¸ª epochï¼ˆå¸¦ tqdmï¼‰"""
    model.eval()

    total_loss = 0.0
    total_dice_score = 0.0
    num_batches = 0

    pbar = tqdm(
        dataloader,
        desc=f"Val   E{epoch+1}/{total_epochs}",
        ncols=120,
        leave=True,
    )

    for images, labels in pbar:
        images = images.to(device, non_blocking=True)
        labels = labels.to(device, non_blocking=True)

        with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):
            seg_logits, normals = model(images)
            loss_total, loss_dice, loss_bce, loss_normal = criterion(seg_logits, normals, labels)

        dice_score = compute_dice(seg_logits, labels)
        total_loss += loss_total.item()
        total_dice_score += dice_score
        num_batches += 1

        pbar.set_postfix({
            'val_loss': f'{total_loss/num_batches:.4f}',
            'val_dice': f'{total_dice_score/num_batches:.4f}',
        })

    pbar.close()

    avg_loss = total_loss / max(num_batches, 1)
    avg_dice = total_dice_score / max(num_batches, 1)

    return {"val_loss": avg_loss, "val_dice": avg_dice}


# ===== ä¸»è®­ç»ƒå‡½æ•° =====

def main(args):
    # è®¾å¤‡
    if args.device == "auto":
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    else:
        device = torch.device(args.device)

    # è¾“å‡ºç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    run_dir = Path(args.output_dir) / f"train_{timestamp}"
    run_dir.mkdir(parents=True, exist_ok=True)

    print(f"\n{'='*70}")
    print(f"  ğŸ”¥ Hybrid Chimera è®­ç»ƒå¼•æ“")
    print(f"  è®¾å¤‡: {device}")
    print(f"  Patch å¤§å°: {args.crop_size}Â³")
    print(f"  Batch Size: {args.batch_size}")
    print(f"  Learning Rate: {args.lr}")
    print(f"  Epochs: {args.epochs}")
    print(f"  Î»_normal: {args.lambda_normal}")
    print(f"  è¾“å‡º: {run_dir}")
    print(f"{'='*70}\n")

    # ===== æ•°æ® =====
    # å¢å¼ºå˜æ¢ï¼šä»… FlipRotateï¼ŒCrop å·²å†…ç½®åˆ° Dataset çš„ memmap __getitem__
    aug_transform = RandomFlipRotate3D(flip_prob=0.5, rotate_prob=0.5)

    full_dataset = VesuviusTrainDataset(
        image_dir=args.image_dir,
        label_dir=args.label_dir,
        crop_size=args.crop_size,
        transform=aug_transform,
        samples_per_volume=args.samples_per_volume,
        cache_size=args.cache_size,
        max_files=args.max_chunks,
    )


    # æŒ‰ 8:2 æ‹†åˆ† train/val
    total_len = len(full_dataset)
    val_len = max(1, int(total_len * 0.2))
    train_len = total_len - val_len

    train_dataset, val_dataset = random_split(
        full_dataset, [train_len, val_len],
        generator=torch.Generator().manual_seed(42),
    )

    print(f"[Data] Train: {train_len} samples, Val: {val_len} samples")

    train_loader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        pin_memory=(device.type == "cuda"),
        drop_last=True,
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=0,
        pin_memory=(device.type == "cuda"),
    )

    # ===== æ¨¡å‹ =====
    model = DualHeadResUNet3D(in_channels=1, n_filters=args.n_filters).to(device)
    params = sum(p.numel() for p in model.parameters())
    print(f"[Model] å‚æ•°é‡: {params:,}")

    # æ¢å¤ checkpoint
    start_epoch = 0
    best_dice = 0.0

    if args.resume and os.path.exists(args.resume):
        ckpt = torch.load(args.resume, map_location=device, weights_only=False)
        if isinstance(ckpt, dict) and "model_state_dict" in ckpt:
            model.load_state_dict(ckpt["model_state_dict"])
            start_epoch = ckpt.get("epoch", 0)
            best_dice = ckpt.get("best_dice", 0.0)
            print(f"[Resume] ä» epoch {start_epoch} æ¢å¤, best_dice={best_dice:.4f}")
        else:
            if any(k.startswith("model.") for k in ckpt.keys()):
                ckpt = {k.replace("model.", ""): v for k, v in ckpt.items()}
            model.load_state_dict(ckpt, strict=False)
            print(f"[Resume] åŠ è½½æƒé‡ï¼ˆæ—  epoch ä¿¡æ¯ï¼‰")

    # ===== ä¼˜åŒ–å™¨ & è°ƒåº¦å™¨ =====
    criterion = ChimeraLoss(
        lambda_normal=args.lambda_normal,
        pos_weight=args.pos_weight,
    ).to(device)
    print(f"[Loss] pos_weight={args.pos_weight}")

    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=args.lr,
        weight_decay=args.weight_decay,
    )

    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=args.epochs,
        eta_min=args.lr * 0.01,
    )

    scaler = torch.amp.GradScaler('cuda', enabled=(device.type == 'cuda'))

    # ===== è®­ç»ƒå¾ªç¯ =====
    print(f"\n{'='*70}")
    print(f"  å¼€å§‹è®­ç»ƒ (epoch {start_epoch+1} â†’ {args.epochs})")
    print(f"{'='*70}\n")

    history = []
    t_total_start = time.time()

    for epoch in range(start_epoch, args.epochs):
        t_ep_start = time.time()
        lr_now = optimizer.param_groups[0]["lr"]

        print(f"\n--- Epoch {epoch+1}/{args.epochs} | LR: {lr_now:.6f} ---")

        # è®­ç»ƒ
        train_metrics = train_one_epoch(
            model, train_loader, criterion, optimizer, scaler,
            device, epoch, args.epochs,
        )

        # éªŒè¯
        val_metrics = validate(model, val_loader, criterion, device, epoch, args.epochs)

        # è°ƒåº¦å™¨
        scheduler.step()

        # æ¯ epoch å¯è§†åŒ–è¾“å‡º
        save_epoch_visualization(
            model, val_loader, device, run_dir, epoch, criterion
        )

        # è®°å½•
        ep_time = time.time() - t_ep_start
        epoch_info = {
            "epoch": epoch + 1,
            "lr": lr_now,
            "time": ep_time,
            **train_metrics,
            **val_metrics,
        }
        history.append(epoch_info)

        # æ‰“å° epoch æ€»ç»“
        print(
            f"\n  ğŸ“Š Epoch {epoch+1} æ€»ç»“:"
            f"\n     Train - Loss: {train_metrics['loss']:.4f} | "
            f"BCE: {train_metrics['bce_loss']:.4f} | "
            f"Dice: {train_metrics['dice_score']:.4f} | "
            f"Normal: {train_metrics['normal_loss']:.4f}"
            f"\n     Val   - Loss: {val_metrics['val_loss']:.4f} | "
            f"Dice: {val_metrics['val_dice']:.4f}"
            f"\n     Time: {format_time(ep_time)} | LR: {lr_now:.6f}"
        )

        # ä¿å­˜ best model
        if val_metrics["val_dice"] > best_dice:
            best_dice = val_metrics["val_dice"]
            best_path = run_dir / "best_model.pth"
            torch.save({
                "epoch": epoch + 1,
                "model_state_dict": model.state_dict(),
                "optimizer_state_dict": optimizer.state_dict(),
                "best_dice": best_dice,
                "args": vars(args),
            }, str(best_path))
            print(f"  ğŸ† New Best Dice: {best_dice:.4f} â†’ {best_path.name}")

        # å®šæœŸä¿å­˜ checkpoint
        if (epoch + 1) % args.save_every == 0:
            ckpt_path = run_dir / f"checkpoint_epoch{epoch+1:03d}.pth"
            torch.save({
                "epoch": epoch + 1,
                "model_state_dict": model.state_dict(),
                "optimizer_state_dict": optimizer.state_dict(),
                "best_dice": best_dice,
                "args": vars(args),
            }, str(ckpt_path))
            print(f"  ğŸ’¾ Checkpoint: {ckpt_path.name}")

    # ===== æœ€ç»ˆæŠ¥å‘Š =====
    total_time = time.time() - t_total_start

    print(f"\n{'='*70}")
    print(f"  è®­ç»ƒå®Œæˆ!")
    print(f"  æ€» Epochs: {args.epochs - start_epoch}")
    print(f"  æ€»è€—æ—¶: {format_time(total_time)}")
    print(f"  æœ€ä½³ Val Dice: {best_dice:.4f}")
    print(f"  è¾“å‡ºç›®å½•: {run_dir}")
    print(f"{'='*70}\n")

    # ä¿å­˜è®­ç»ƒå†å²
    history_path = run_dir / "training_history.json"
    with open(str(history_path), "w", encoding="utf-8") as f:
        json.dump(history, f, indent=2, ensure_ascii=False)
    print(f"  ğŸ“ˆ è®­ç»ƒå†å²: {history_path.name}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Hybrid Chimera è®­ç»ƒå¼•æ“")

    # æ•°æ®å‚æ•°
    parser.add_argument("--image_dir", type=str,
                        default="data/vesuvius-challenge-surface-detection/train_images")
    parser.add_argument("--label_dir", type=str,
                        default="data/vesuvius-challenge-surface-detection/train_labels")
    parser.add_argument("--max_chunks", type=int, default=None,
                        help="æœ€å¤šä½¿ç”¨å¤šå°‘ä¸ª chunkï¼ˆè°ƒè¯•ç”¨ï¼‰")
    parser.add_argument("--samples_per_volume", type=int, default=4,
                        help="æ¯ä¸ªä½“ç§¯æ¯ epoch é‡‡é›†å‡ ä¸ª patch")
    parser.add_argument("--cache_size", type=int, default=8,
                        help="LRU ç¼“å­˜ä½“ç§¯æ•°é‡")

    # è®­ç»ƒå‚æ•°
    parser.add_argument("--epochs", type=int, default=50)
    parser.add_argument("--batch_size", type=int, default=8)
    parser.add_argument("--lr", type=float, default=1e-3)
    parser.add_argument("--weight_decay", type=float, default=1e-4)
    parser.add_argument("--crop_size", type=int, default=64,
                        help="Random Crop 3D å°ºå¯¸")
    parser.add_argument("--lambda_normal", type=float, default=1.0,
                        help="æ³•çº¿æŸå¤±æƒé‡")
    parser.add_argument("--pos_weight", type=float, default=10.0,
                        help="BCE æ­£æ ·æœ¬æƒé‡ (è¶Šå¤§è¶Šå¼ºè°ƒ Recallï¼Œè¶Šå°è¶Šå¼ºè°ƒ Precision)")
    parser.add_argument("--n_filters", type=int, default=32,
                        help="æ¨¡å‹åŸºç¡€æ»¤æ³¢å™¨æ•°")
    parser.add_argument("--num_workers", type=int, default=0,
                        help="DataLoader å·¥ä½œè¿›ç¨‹æ•°")

    # ä¿å­˜å‚æ•°
    parser.add_argument("--output_dir", type=str, default="20_src/output")
    parser.add_argument("--save_every", type=int, default=10,
                        help="æ¯å‡ ä¸ª epoch ä¿å­˜ checkpoint")
    parser.add_argument("--resume", type=str, default=None,
                        help="æ¢å¤è®­ç»ƒçš„ checkpoint è·¯å¾„")

    # è®¾å¤‡
    parser.add_argument("--device", type=str, default="auto")

    args = parser.parse_args()
    main(args)

```

---
## File: verify_data.py
```py
"""
Vesuvius Challenge - æ•°æ®éªŒè¯è„šæœ¬

åŠŸèƒ½ï¼šæ£€æŸ¥é¢„å¤„ç†åçš„ NPY æ ‡ç­¾æ–‡ä»¶çš„ç¨€ç–æ€§ï¼Œç¡®ä¿æ¨¡å‹è®­ç»ƒåœ¨æ­£ç¡®çš„ç›®æ ‡ä¸Šã€‚
ç›®çš„ï¼šé˜²æ­¢"è®­ç»ƒåœ¨å®å¿ƒ Mask ä¸Š"çš„è‡´å‘½é”™è¯¯å†æ¬¡å‘ç”Ÿã€‚

æ­£ç¡®çš„æ ‡ç­¾åº”è¯¥éå¸¸ç¨€ç–ï¼ˆçº¸è‰è¡¨é¢ ~5%ï¼‰ï¼Œè€Œä¸æ˜¯å®å¿ƒå—ã€‚

ç”¨æ³•:
    python 20_src/verify_data.py
"""

import sys
from pathlib import Path
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt


def verify_labels(label_dir: str, num_samples: int = 5, save_png: bool = True):
    """
    éªŒè¯æ ‡ç­¾æ–‡ä»¶çš„å†…å®¹å’Œç¨€ç–æ€§

    Args:
        label_dir: NPY æ ‡ç­¾ç›®å½•
        num_samples: éšæœºæŠ½æ ·æ£€æŸ¥çš„æ–‡ä»¶æ•°é‡
        save_png: æ˜¯å¦ä¿å­˜åˆ‡ç‰‡å¯è§†åŒ– PNG
    """
    label_path = Path(label_dir)
    if not label_path.exists():
        print(f"âŒ æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: {label_path}")
        sys.exit(1)

    npy_files = sorted(label_path.glob("*.npy"))
    if len(npy_files) == 0:
        print(f"âŒ æœªæ‰¾åˆ° .npy æ–‡ä»¶: {label_path}")
        sys.exit(1)

    print(f"{'='*60}")
    print(f"  ğŸ”¬ Vesuvius æ ‡ç­¾æ•°æ®éªŒè¯")
    print(f"  ç›®å½•: {label_path}")
    print(f"  æ–‡ä»¶æ•°: {len(npy_files)}")
    print(f"{'='*60}\n")

    # éšæœºæŠ½æ ·
    rng = np.random.default_rng(42)
    sample_indices = rng.choice(len(npy_files), size=min(num_samples, len(npy_files)), replace=False)
    sample_files = [npy_files[i] for i in sorted(sample_indices)]

    all_sparsities = []
    fatal_errors = []

    for f in sample_files:
        vol = np.load(str(f), mmap_mode='r')
        total = vol.size
        unique_vals = np.unique(vol)

        # ç»Ÿè®¡å„å€¼å æ¯”
        count_0 = np.sum(vol == 0)
        count_1 = np.sum(vol == 1)
        count_2 = np.sum(vol == 2)

        # è®¡ç®—ç¨€ç–åº¦ï¼ˆval=1 æ˜¯ç›®æ ‡ï¼‰
        surface_ratio = count_1 / total
        ignore_ratio = count_2 / total
        bg_ratio = count_0 / total

        all_sparsities.append(surface_ratio)

        # çŠ¶æ€åˆ¤æ–­
        status = "âœ…"
        if surface_ratio > 0.30:
            status = "âš ï¸ WARNING"
        if surface_ratio > 0.90:
            status = "âŒ FATAL"
            fatal_errors.append(f.name)

        print(f"{status} {f.name}:")
        print(f"    shape={vol.shape}, dtype={vol.dtype}, unique={unique_vals}")
        print(f"    èƒŒæ™¯(0): {bg_ratio*100:.1f}% | "
              f"è¡¨é¢(1): {surface_ratio*100:.1f}% | "
              f"å¿½ç•¥(2): {ignore_ratio*100:.1f}%")
        print()

    # æ€»ç»“
    avg_sparsity = np.mean(all_sparsities)
    print(f"{'='*60}")
    print(f"  ğŸ“Š æ±‡æ€»ç»Ÿè®¡")
    print(f"  å¹³å‡è¡¨é¢å æ¯” (val=1): {avg_sparsity*100:.2f}%")
    print(f"{'='*60}")

    if avg_sparsity < 0.10:
        print(f"\n  âœ… æ•°æ®æ­£å¸¸ï¼è¡¨é¢æ ‡ç­¾ç¨€ç–åº¦åˆç† ({avg_sparsity*100:.1f}% < 10%)")
        print(f"  â†’ æ¨¡å‹åº”è¯¥å­¦ä¹ ç”»'ç¨€ç–çš„çº¿æ¡'ï¼Œè€Œé'å®å¿ƒæ–¹å—'")
    elif avg_sparsity < 0.30:
        print(f"\n  âš ï¸ æ³¨æ„ï¼šè¡¨é¢å æ¯”åé«˜ ({avg_sparsity*100:.1f}%)ï¼Œä½†å¯èƒ½ä»ç„¶åˆç†")
    else:
        print(f"\n  âŒ ä¸¥é‡é—®é¢˜ï¼è¡¨é¢å æ¯”è¿‡é«˜ ({avg_sparsity*100:.1f}%)ï¼Œ"
              f"å¯èƒ½ä»åœ¨ä½¿ç”¨é”™è¯¯çš„æ ‡ç­¾ï¼")

    if fatal_errors:
        print(f"\n  âŒ FATAL: ä»¥ä¸‹æ–‡ä»¶çš„æ­£æ ·æœ¬æ¯”ä¾‹ > 90%: {fatal_errors}")
        sys.exit(1)

    # ç”Ÿæˆå¯è§†åŒ–
    if save_png:
        sample_vol = np.load(str(sample_files[0]))
        mid_z = sample_vol.shape[0] // 2

        fig, axes = plt.subplots(1, 3, figsize=(15, 5))

        # åŸå§‹æ ‡ç­¾ (0, 1, 2)
        axes[0].imshow(sample_vol[mid_z], cmap='tab10', vmin=0, vmax=2)
        axes[0].set_title(f'åŸå§‹æ ‡ç­¾ (z={mid_z})\n0=èƒŒæ™¯, 1=è¡¨é¢, 2=å¿½ç•¥')

        # åªçœ‹ val=1 (è¡¨é¢)
        surface = (sample_vol[mid_z] == 1).astype(np.float32)
        axes[1].imshow(surface, cmap='hot', vmin=0, vmax=1)
        sr = np.sum(surface) / surface.size * 100
        axes[1].set_title(f'è¡¨é¢ (val=1)\nç¨€ç–åº¦: {sr:.1f}%')

        # åªçœ‹ val=2 (å¿½ç•¥åŒºåŸŸ)
        ignore = (sample_vol[mid_z] == 2).astype(np.float32)
        axes[2].imshow(ignore, cmap='Blues', vmin=0, vmax=1)
        ir = np.sum(ignore) / ignore.size * 100
        axes[2].set_title(f'å¿½ç•¥åŒºåŸŸ (val=2)\nå æ¯”: {ir:.1f}%')

        for ax in axes:
            ax.axis('off')

        fig.suptitle(f'æ–‡ä»¶: {sample_files[0].name}', fontsize=12, fontweight='bold')
        plt.tight_layout()

        out_path = Path("20_src/output/verification_slice.png")
        out_path.parent.mkdir(parents=True, exist_ok=True)
        plt.savefig(str(out_path), dpi=150, bbox_inches='tight')
        plt.close()
        print(f"\n  ğŸ“¸ å¯è§†åŒ–å·²ä¿å­˜: {out_path}")


if __name__ == "__main__":
    verify_labels("data/vesuvius-challenge-surface-detection/train_labels_npy")

```

---
## File: winding_solver.py
```py
"""
Vesuvius Challenge - Winding Number Solver (MVP)

æ›¿ä»£ ThaumatoAnakalyptor C++ æ±‚è§£å™¨çš„çº¯ Python å®ç°ã€‚

æ ¸å¿ƒæ€æƒ³ï¼š
1. ä»ç¨€ç–é‚»æ¥å›¾æ„å»º Graph Laplacian L = D - A
2. è®¾å®š Dirichlet è¾¹ç•Œæ¡ä»¶ï¼ˆseed èŠ‚ç‚¹: å†…éƒ¨=1, å¤–éƒ¨=0ï¼‰
3. æ±‚è§£ L_ff * u_f = -L_fs * u_sï¼ˆçƒ­æ‰©æ•£é—®é¢˜ï¼‰
4. é˜ˆå€¼åŒ– winding number åœºç”Ÿæˆæœ€ç»ˆ binary mask

æ”¯æŒ GPU (CuPy) å’Œ CPU (SciPy) åŒè·¯å¾„ã€‚
"""

import numpy as np
from scipy import sparse
from scipy.sparse import linalg as sp_linalg
from typing import Dict, Optional, Tuple


def solve_winding_number(
    adjacency: sparse.csr_matrix,
    seeds: Dict[int, float],
    use_cupy: bool = False,
    tol: float = 1e-6,
    maxiter: int = 5000,
) -> np.ndarray:
    """
    æ±‚è§£ Winding Number æ ‡é‡åœº

    é€šè¿‡æ±‚è§£ Laplacian çº¿æ€§ç³»ç»Ÿ + Dirichlet è¾¹ç•Œæ¡ä»¶ï¼Œ
    å°† seed èŠ‚ç‚¹çš„æ ‡é‡å€¼æ‰©æ•£åˆ°æ•´ä¸ªè¿é€šå›¾ä¸Šã€‚

    Args:
        adjacency: ç¨€ç–é‚»æ¥çŸ©é˜µ (N, N)ï¼Œæ¥è‡ª build_sparse_graph
        seeds: è¾¹ç•Œæ¡ä»¶å­—å…¸ {èŠ‚ç‚¹ç´¢å¼•: å€¼}
               ä¾‹å¦‚ {0: 0.0, 10: 1.0} â†’ èŠ‚ç‚¹ 0 æ˜¯å¤–éƒ¨ï¼ŒèŠ‚ç‚¹ 10 æ˜¯å†…éƒ¨
        use_cupy: æ˜¯å¦ä½¿ç”¨ CuPy GPU åŠ é€Ÿï¼Œé»˜è®¤ False
        tol: æ±‚è§£å™¨æ”¶æ•›å®¹å·®
        maxiter: æœ€å¤§è¿­ä»£æ¬¡æ•°

    Returns:
        u: np.ndarrayï¼Œå½¢çŠ¶ (N,)ï¼Œæ¯ä¸ªèŠ‚ç‚¹çš„ winding number å€¼
           u â‰ˆ 1.0 â†’ å†…éƒ¨ï¼Œu â‰ˆ 0.0 â†’ å¤–éƒ¨

    Raises:
        ValueError: æ— æ•ˆè¾“å…¥æ—¶æŠ›å‡º
    """
    N = adjacency.shape[0]

    if N == 0:
        return np.array([], dtype=np.float64)

    if len(seeds) == 0:
        print("[solve_winding_number] è­¦å‘Š: æ—  seed èŠ‚ç‚¹ï¼Œè¿”å›å…¨é›¶è§£")
        return np.zeros(N, dtype=np.float64)

    # --- è¿é€šæ€§é¢„æ£€ (Diagnostics) ---
    from scipy.sparse.csgraph import connected_components
    n_components, labels = connected_components(adjacency, connection='strong', directed=False)
    
    if n_components > 1:
        print(f"[solve_winding_number] âš ï¸ è­¦å‘Š: å›¾åŒ…å« {n_components} ä¸ªä¸è¿é€šçš„å­å›¾ (æ‹“æ‰‘æ–­è£‚é£é™©)")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å­å›¾å®Œå…¨æ²¡æœ‰ç§å­
        seed_mask = np.zeros(N, dtype=bool)
        for idx in seeds.keys():
            seed_mask[idx] = True
            
        # ç»Ÿè®¡æ¯ä¸ª component æ˜¯å¦æœ‰ seed
        components_with_seeds = 0
        for k in range(n_components):
            comp_nodes = np.where(labels == k)[0]
            if np.any(seed_mask[comp_nodes]):
                components_with_seeds += 1
                
        if components_with_seeds < n_components:
            print(f"  ğŸ›‘ è‡´å‘½: {n_components - components_with_seeds} ä¸ªå­å›¾å®Œå…¨æ²¡æœ‰ Seedï¼Œå°†å¯¼è‡´æ— è§£æˆ–å…¨0ï¼")
            print("  å»ºè®®: æ£€æŸ¥ U-Net é¢„æµ‹æ˜¯å¦è¿‡åº¦ç ´ç¢ï¼Œæˆ–æ”¹è¿› Seed åˆ†é…ç­–ç•¥")

    # --- æ­¥éª¤ 1: æ„å»º Graph Laplacian ---
    degree = np.array(adjacency.sum(axis=1)).flatten()
    # é˜²æ­¢å­¤ç«‹èŠ‚ç‚¹ï¼ˆåº¦ä¸º 0ï¼‰å¯¼è‡´å¥‡å¼‚çŸ©é˜µ
    degree = np.maximum(degree, 1e-10)
    D = sparse.diags(degree, format='csr')
    L = D - adjacency  # Laplacian = D - A

    # --- æ­¥éª¤ 2: åˆ†ç¦» seed (s) å’Œ free (f) èŠ‚ç‚¹ ---
    seed_indices = sorted(seeds.keys())
    seed_values = np.array([seeds[i] for i in seed_indices], dtype=np.float64)

    all_indices = np.arange(N)
    seed_set = set(seed_indices)
    free_indices = np.array([i for i in all_indices if i not in seed_set])

    if len(free_indices) == 0:
        # æ‰€æœ‰èŠ‚ç‚¹éƒ½æ˜¯ seedï¼Œç›´æ¥èµ‹å€¼
        u = np.zeros(N, dtype=np.float64)
        for idx, val in seeds.items():
            u[idx] = val
        return u

    # --- æ­¥éª¤ 3: æå–å­çŸ©é˜µ ---
    # L_ff: free-free å­çŸ©é˜µ
    # L_fs: free-seed å­çŸ©é˜µ
    seed_arr = np.array(seed_indices)

    L_ff = L[np.ix_(free_indices, free_indices)]
    L_fs = L[np.ix_(free_indices, seed_arr)]

    # å³ç«¯é¡¹: b = -L_fs * u_s
    rhs = -L_fs.dot(seed_values)

    print(f"[solve_winding_number] æ±‚è§£çº¿æ€§ç³»ç»Ÿ: "
          f"{len(free_indices)} ä¸ªè‡ªç”±èŠ‚ç‚¹, {len(seed_indices)} ä¸ªç§å­èŠ‚ç‚¹")

    # --- æ­¥éª¤ 4: æ±‚è§£ L_ff * u_f = rhs ---
    if use_cupy:
        try:
            import cupy as cp
            import cupyx.scipy.sparse as cp_sparse
            import cupyx.scipy.sparse.linalg as cp_linalg

            # è½¬ç§»åˆ° GPU
            L_ff_gpu = cp_sparse.csr_matrix(L_ff)
            rhs_gpu = cp.array(rhs)

            # å…±è½­æ¢¯åº¦æ±‚è§£
            u_f_gpu, info = cp_linalg.cg(L_ff_gpu, rhs_gpu, atol=tol, maxiter=maxiter)

            if info != 0:
                print(f"[solve_winding_number] CuPy CG æœªæ”¶æ•› (info={info})ï¼Œ"
                      f"å›é€€åˆ° CPU")
                raise RuntimeError("CuPy CG æœªæ”¶æ•›")

            u_f = cp.asnumpy(u_f_gpu)
            print("[solve_winding_number] ä½¿ç”¨ CuPy GPU æ±‚è§£å®Œæˆ")

        except (ImportError, RuntimeError) as e:
            print(f"[solve_winding_number] CuPy ä¸å¯ç”¨æˆ–å¤±è´¥: {e}ï¼Œå›é€€åˆ° CPU")
            use_cupy = False

    if not use_cupy:
        # CPU è·¯å¾„: SciPy å…±è½­æ¢¯åº¦
        u_f, info = sp_linalg.cg(L_ff, rhs, atol=tol, maxiter=maxiter)

        if info != 0:
            print(f"[solve_winding_number] SciPy CG æ”¶æ•›çŠ¶æ€: info={info}")
            if info > 0:
                print("  â†’ æœªåœ¨æœ€å¤§è¿­ä»£æ¬¡æ•°å†…æ”¶æ•›ï¼Œç»“æœå¯èƒ½ä¸ç²¾ç¡®")
            else:
                print("  â†’ è¾“å…¥çŸ©é˜µå­˜åœ¨é—®é¢˜")

        print("[solve_winding_number] ä½¿ç”¨ SciPy CPU æ±‚è§£å®Œæˆ")

    # --- æ­¥éª¤ 5: ç»„è£…å®Œæ•´è§£å‘é‡ ---
    u = np.zeros(N, dtype=np.float64)

    # å¡«å…¥ seed å€¼
    for idx, val in seeds.items():
        u[idx] = val

    # å¡«å…¥è‡ªç”±èŠ‚ç‚¹çš„è§£
    u[free_indices] = u_f

    # Clip åˆ°åˆç†èŒƒå›´
    u = np.clip(u, 0.0, 1.0)

    print(f"[solve_winding_number] è§£çš„èŒƒå›´: [{u.min():.4f}, {u.max():.4f}]")

    return u


def cut_mesh(
    winding_field: np.ndarray,
    node_coords: np.ndarray,
    volume_shape: Tuple[int, int, int],
    threshold: float = 0.5,
) -> np.ndarray:
    """
    å°† winding number æ ‡é‡åœºæ˜ å°„å›ä½“ç§¯ç©ºé—´ï¼Œç”Ÿæˆ binary mask

    Args:
        winding_field: æ¯ä¸ªèŠ‚ç‚¹çš„ winding numberï¼Œå½¢çŠ¶ (N,)
        node_coords: èŠ‚ç‚¹åæ ‡ï¼Œå½¢çŠ¶ (N, 3)ï¼Œæ¯è¡Œ (d, h, w)
        volume_shape: è¾“å‡ºä½“ç§¯çš„å½¢çŠ¶ (D, H, W)
        threshold: é˜ˆå€¼ï¼Œu >= threshold â†’ 1ï¼ˆå†…éƒ¨ï¼‰ï¼Œé»˜è®¤ 0.5

    Returns:
        mask: binary maskï¼Œå½¢çŠ¶ (D, H, W)ï¼Œdtype=float32
    """
    D, H, W = volume_shape
    mask = np.zeros((D, H, W), dtype=np.float32)

    if len(winding_field) == 0:
        return mask

    # å°†æ¯ä¸ªèŠ‚ç‚¹çš„ winding number å†™å…¥å¯¹åº”ä½ç½®
    for i, (d, h, w) in enumerate(node_coords):
        d, h, w = int(d), int(h), int(w)
        if 0 <= d < D and 0 <= h < H and 0 <= w < W:
            mask[d, h, w] = winding_field[i]

    # é˜ˆå€¼åŒ–
    binary_mask = (mask >= threshold).astype(np.float32)

    num_inside = int(binary_mask.sum())
    total = D * H * W
    print(f"[cut_mesh] å†…éƒ¨ä½“ç´ : {num_inside} / {total} "
          f"(å æ¯” {num_inside / total * 100:.1f}%)")

    return binary_mask


def auto_assign_seeds(
    node_coords: np.ndarray,
    volume_shape: Tuple[int, int, int],
    boundary_thickness: int = 2,
) -> Dict[int, float]:
    """
    è‡ªåŠ¨åˆ†é… seed èŠ‚ç‚¹çš„è¾…åŠ©å‡½æ•°

    ç­–ç•¥ï¼š
    - é è¿‘ä½“ç§¯è¾¹ç•Œçš„èŠ‚ç‚¹ â†’ å¤–éƒ¨ (u=0)
    - é è¿‘ä½“ç§¯ä¸­å¿ƒçš„èŠ‚ç‚¹ â†’ å†…éƒ¨ (u=1)

    Args:
        node_coords: èŠ‚ç‚¹åæ ‡ï¼Œå½¢çŠ¶ (N, 3)
        volume_shape: ä½“ç§¯å½¢çŠ¶ (D, H, W)
        boundary_thickness: è¾¹ç•Œå±‚åšåº¦ï¼ˆä½“ç´ æ•°ï¼‰ï¼Œé»˜è®¤ 2

    Returns:
        seeds: {èŠ‚ç‚¹ç´¢å¼•: å€¼} å­—å…¸
    """
    D, H, W = volume_shape
    seeds = {}

    center = np.array([D / 2, H / 2, W / 2])

    for i, coord in enumerate(node_coords):
        d, h, w = coord

        # åˆ¤æ–­æ˜¯å¦åœ¨è¾¹ç•Œå±‚
        is_boundary = (
            d < boundary_thickness or d >= D - boundary_thickness or
            h < boundary_thickness or h >= H - boundary_thickness or
            w < boundary_thickness or w >= W - boundary_thickness
        )

        if is_boundary:
            seeds[i] = 0.0  # å¤–éƒ¨

    # æ‰¾åˆ°æœ€é è¿‘ä¸­å¿ƒçš„èŠ‚ç‚¹ä½œä¸ºå†…éƒ¨ seed
    if len(node_coords) > 0:
        distances = np.linalg.norm(node_coords - center, axis=1)
        center_node = int(np.argmin(distances))
        if center_node not in seeds:
            seeds[center_node] = 1.0  # å†…éƒ¨

    print(f"[auto_assign_seeds] è‡ªåŠ¨åˆ†é…äº† {len(seeds)} ä¸ªç§å­èŠ‚ç‚¹ "
          f"(å¤–éƒ¨: {sum(1 for v in seeds.values() if v == 0.0)}, "
          f"å†…éƒ¨: {sum(1 for v in seeds.values() if v == 1.0)})")

    return seeds


if __name__ == "__main__":
    print("=== Winding Number Solver è‡ªæµ‹ ===")

    # å¯¼å…¥ graph_builderï¼ˆä½¿ç”¨ importlib å¤„ç†æ•°å­—å¼€å¤´çš„æ¨¡å—åï¼‰
    import sys
    import os
    # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.path
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    if project_root not in sys.path:
        sys.path.insert(0, project_root)

    from importlib import import_module
    gb = import_module("20_src.graph_builder")

    # --- åˆ›å»ºåˆæˆæ•°æ® ---
    D, H, W = 8, 8, 8
    prob_map = np.zeros((D, H, W), dtype=np.float32)
    prob_map[1:7, 1:7, 1:7] = 0.8  # ä¸­å¿ƒ 6x6x6 åŒºåŸŸæœ‰æ•ˆ

    normal_map = np.zeros((3, D, H, W), dtype=np.float32)
    normal_map[2, :, :, :] = 1.0  # æ³•çº¿å…¨éƒ¨æŒ‡å‘ z

    # --- æ„å»ºå›¾ ---
    adj, coords, idx_map = gb.build_sparse_graph(prob_map, normal_map)
    print(f"å›¾: {len(coords)} èŠ‚ç‚¹, {adj.nnz} è¾¹")

    # --- è‡ªåŠ¨åˆ†é… seeds ---
    seeds = auto_assign_seeds(coords, (D, H, W))
    print(f"Seeds: {len(seeds)} ä¸ª")

    # --- æ±‚è§£ winding number ---
    u = solve_winding_number(adj, seeds)
    print(f"è§£å‘é‡é•¿åº¦: {len(u)}")
    print(f"è§£çš„èŒƒå›´: [{u.min():.4f}, {u.max():.4f}]")

    # --- ç”Ÿæˆ mask ---
    mask = cut_mesh(u, coords, (D, H, W), threshold=0.5)
    print(f"Mask å½¢çŠ¶: {mask.shape}")
    print(f"Mask éé›¶: {mask.sum():.0f}")

    # åŸºæœ¬æ–­è¨€
    assert len(u) == len(coords), "è§£å‘é‡é•¿åº¦åº”ç­‰äºèŠ‚ç‚¹æ•°"
    assert mask.shape == (D, H, W), f"Mask å½¢çŠ¶é”™è¯¯: {mask.shape}"
    assert u.min() >= 0.0 and u.max() <= 1.0, "è§£åº”åœ¨ [0, 1] èŒƒå›´å†…"

    print("âœ“ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")

```

---
## File: 20_data\__init__.py
```py
# 20_data: æ•°æ®åŠ è½½æ¨¡å—
from .dataset import TifChunkDataset

```

---
## File: 20_data\dataset.py
```py
"""
Vesuvius Challenge - 3D TIF Chunk æ•°æ®åŠ è½½å™¨

åŒ…å«ä¸¤ä¸ª Datasetï¼š
- TifChunkDataset:       æ¨ç†ç”¨ï¼Œæ•´ä½“åŠ è½½
- VesuviusTrainDataset:  è®­ç»ƒç”¨ï¼ŒNPY mmap é›¶æ‹·è´ / TIF LRU ç¼“å­˜

æ ¸å¿ƒä¼˜åŒ–ï¼ˆNPY æ¨¡å¼ï¼‰ï¼š
  np.load(mmap_mode='r') å°†æ–‡ä»¶æ˜ å°„åˆ°è™šæ‹Ÿå†…å­˜ï¼Œ
  åªæœ‰åœ¨ slice æ—¶æ‰è§¦å‘ç¼ºé¡µä¸­æ–­è¯»å–å¯¹åº”çš„å­—èŠ‚ã€‚
  96Â³ uint8 patch â‰ˆ 0.88MBï¼ŒIO æ—¶é—´ < 1msã€‚
"""

import os
from pathlib import Path
from typing import Optional, Callable, List, Union
from collections import OrderedDict

import numpy as np
import torch
from torch.utils.data import Dataset
import tifffile


class TifChunkDataset(Dataset):
    """
    3D TIF Chunk æ•°æ®é›†ï¼ˆæ¨ç†ç”¨ï¼‰

    ä»æŒ‡å®šç›®å½•ä¸­æ‰«ææ‰€æœ‰ .tif/.tiff æ–‡ä»¶ï¼Œé€ä¸ªæ•´ä½“åŠ è½½ä¸º 3D tensorã€‚
    """

    def __init__(
        self,
        data_source: Union[str, Path, List[str]],
        transform: Optional[Callable] = None,
        normalize: bool = True,
    ):
        super().__init__()
        self.transform = transform
        self.normalize = normalize

        if isinstance(data_source, (str, Path)):
            data_source = Path(data_source)
            if data_source.is_dir():
                self.file_paths = sorted([
                    str(p) for p in data_source.iterdir()
                    if p.suffix.lower() in ('.tif', '.tiff')
                ])
            elif data_source.is_file():
                self.file_paths = [str(data_source)]
            else:
                raise FileNotFoundError(f"æ•°æ®æºä¸å­˜åœ¨: {data_source}")
        elif isinstance(data_source, list):
            self.file_paths = [str(p) for p in data_source]
        else:
            raise TypeError(f"ä¸æ”¯æŒçš„æ•°æ®æºç±»å‹: {type(data_source)}")

        if len(self.file_paths) == 0:
            raise ValueError("æœªæ‰¾åˆ°ä»»ä½• .tif æ–‡ä»¶")

        print(f"[TifChunkDataset] åŠ è½½äº† {len(self.file_paths)} ä¸ª chunk æ–‡ä»¶")

    def __len__(self) -> int:
        return len(self.file_paths)

    def __getitem__(self, idx: int) -> torch.Tensor:
        file_path = self.file_paths[idx]
        volume = tifffile.imread(file_path)

        if volume.ndim == 2:
            volume = volume[np.newaxis, ...]
        elif volume.ndim != 3:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®ç»´åº¦ {volume.ndim}Dï¼Œæ–‡ä»¶: {file_path}")

        volume = volume.astype(np.float32)
        if self.normalize:
            volume = self._normalize(volume)
        if self.transform is not None:
            volume = self.transform(volume)

        return torch.from_numpy(volume).unsqueeze(0)

    def _normalize(self, data: np.ndarray) -> np.ndarray:
        max_val = data.max()
        if max_val <= 1.0 + 1e-6:
            return np.clip(data, 0.0, 1.0)
        elif max_val <= 255.0 + 1e-6:
            return data / 255.0
        else:
            return data / 65535.0

    def get_file_path(self, idx: int) -> str:
        return self.file_paths[idx]


# ===================================================================
#  é«˜æ€§èƒ½è®­ç»ƒ Dataset
# ===================================================================

class VesuviusTrainDataset(Dataset):
    """
    Vesuvius è®­ç»ƒæ•°æ®é›†ï¼ˆé«˜æ€§èƒ½ç‰ˆï¼‰

    è‡ªåŠ¨æ£€æµ‹é¢„å¤„ç†çš„ NPY æ–‡ä»¶ï¼Œä¼˜å…ˆä½¿ç”¨ mmap é›¶æ‹·è´æ¨¡å¼ã€‚
    è‹¥ NPY ä¸å­˜åœ¨åˆ™å›é€€åˆ° TIF + LRU ç¼“å­˜ã€‚

    æ€§èƒ½å¯¹æ¯”ï¼š
      NPY mmap: ~0.1ms/sample (é›¶æ‹·è´åˆ‡ç‰‡)
      TIF cache hit: ~0.1ms/sample (å†…å­˜ç¼“å­˜)
      TIF cache miss: ~100ms/sample (è§£å‹ LZW)

    Args:
        image_dir:  train_images ç›®å½•
        label_dir:  train_labels ç›®å½•
        crop_size:  3D éšæœºè£å‰ªå°ºå¯¸
        transform:  è£å‰ªåçš„å¢å¼ºå˜æ¢ (æ¥å— (image, label) è¿”å› (image, label))
        samples_per_volume: æ¯ä¸ªä½“ç§¯æ¯ epoch é‡‡å‡ ä¸ª patch
        cache_size: TIF æ¨¡å¼ä¸‹çš„ LRU ç¼“å­˜ä½“ç§¯æ•°é‡
        max_files:  æœ€å¤šä½¿ç”¨å¤šå°‘ä¸ªæ–‡ä»¶ï¼ˆNone=å…¨éƒ¨ï¼‰
    """

    def __init__(
        self,
        image_dir: Union[str, Path],
        label_dir: Union[str, Path],
        crop_size: int = 96,
        transform: Optional[Callable] = None,
        samples_per_volume: int = 16,
        cache_size: int = 32,
        max_files: Optional[int] = None,
        pos_ratio: float = 0.7,
    ):
        super().__init__()
        self.transform = transform
        self.samples_per_volume = samples_per_volume
        self.cache_size = cache_size
        self.pos_ratio = pos_ratio  # æ­£æ ·æœ¬å¼ºåˆ¶é‡‡æ ·æ¯”ä¾‹ï¼ˆæ‹’ç»é‡‡æ ·ï¼‰

        # è£å‰ªå°ºå¯¸
        if isinstance(crop_size, int):
            self.crop_size = (crop_size, crop_size, crop_size)
        else:
            self.crop_size = tuple(crop_size)

        image_dir = Path(image_dir)
        label_dir = Path(label_dir)

        # ====== ä¼˜å…ˆæ£€æµ‹ NPY ç›®å½• ======
        npy_image_dir = image_dir.parent / (image_dir.name + "_npy")
        npy_label_dir = label_dir.parent / (label_dir.name + "_npy")

        self.use_npy = False
        if npy_image_dir.exists() and npy_label_dir.exists():
            image_files = {p.stem: p for p in sorted(npy_image_dir.glob("*.npy"))}
            label_files = {p.stem: p for p in sorted(npy_label_dir.glob("*.npy"))}
            if len(image_files) > 0 and len(label_files) > 0:
                self.use_npy = True
                print(f"[Dataset] ğŸš€ å‘ç°é¢„å¤„ç† NPY æ•°æ® "
                      f"({len(image_files)} img + {len(label_files)} lbl)ï¼Œ"
                      f"å¯ç”¨æé€Ÿ mmap æ¨¡å¼ï¼")
            else:
                print("[Dataset] NPY ç›®å½•ä¸ºç©ºï¼Œå›é€€åˆ° TIF æ¨¡å¼")

        if not self.use_npy:
            # å›é€€åˆ° TIF
            image_files = {
                p.stem: p for p in sorted(image_dir.iterdir())
                if p.suffix.lower() in ('.tif', '.tiff')
            }
            label_files = {
                p.stem: p for p in sorted(label_dir.iterdir())
                if p.suffix.lower() in ('.tif', '.tiff')
            }
            print(f"[Dataset] ä½¿ç”¨ TIF æ¨¡å¼ + LRU ç¼“å­˜ (cache_size={cache_size})")

        # é…å¯¹
        common_ids = sorted(set(image_files.keys()) & set(label_files.keys()))
        if max_files is not None:
            common_ids = common_ids[:max_files]

        self.pairs = [
            (str(image_files[cid]), str(label_files[cid]))
            for cid in common_ids
        ]

        if len(self.pairs) == 0:
            raise ValueError(
                f"æœªæ‰¾åˆ° image-label é…å¯¹ï¼\n"
                f"  image_dir: {image_dir}\n"
                f"  label_dir: {label_dir}"
            )

        # é¢„æ‰«æä½“ç§¯ shape
        self._shapes = []
        if self.use_npy:
            # NPY: è¯» header è·å– shapeï¼ˆæå¿«ï¼‰
            for img_path, _ in self.pairs:
                arr = np.load(img_path, mmap_mode='r')
                self._shapes.append(arr.shape)
        else:
            # TIF: è¯»æ–‡ä»¶å¤´
            for img_path, _ in self.pairs:
                with tifffile.TiffFile(img_path) as tif:
                    self._shapes.append(tif.series[0].shape)

        # TIF æ¨¡å¼ä¸‹çš„ LRU ç¼“å­˜
        self._cache = OrderedDict()

        print(f"[VesuviusTrainDataset] {len(self.pairs)} ä¸ªé…å¯¹, "
              f"crop={self.crop_size}, {samples_per_volume} samples/vol, "
              f"æ€»è®¡ {len(self)} ä¸ªè®­ç»ƒæ ·æœ¬/epoch")

    def __len__(self) -> int:
        return len(self.pairs) * self.samples_per_volume

    def _load_volume(self, vol_idx: int):
        """
        åŠ è½½ä½“ç§¯æ•°æ®

        NPY æ¨¡å¼: np.load(mmap_mode='r') â†’ è¿”å› mmap å¯¹è±¡ï¼Œé›¶ RAM å¼€é”€
        TIF æ¨¡å¼: imread + LRU ç¼“å­˜
        """
        if self.use_npy:
            img_path, lbl_path = self.pairs[vol_idx]
            image = np.load(img_path, mmap_mode='r')
            label = np.load(lbl_path, mmap_mode='r')
            return image, label

        # TIF LRU ç¼“å­˜
        if vol_idx in self._cache:
            self._cache.move_to_end(vol_idx)
            return self._cache[vol_idx]

        img_path, lbl_path = self.pairs[vol_idx]
        image = tifffile.imread(img_path)
        label = tifffile.imread(lbl_path)

        self._cache[vol_idx] = (image, label)
        if len(self._cache) > self.cache_size:
            self._cache.popitem(last=False)

        return image, label

    def _random_crop_coords(self, vol_shape):
        """è®¡ç®—éšæœºè£å‰ªåæ ‡ï¼Œå¤„ç†å°ä½“ç§¯ padding"""
        coords = []
        pads = []
        for dim_size, crop_dim in zip(vol_shape, self.crop_size):
            if dim_size >= crop_dim:
                start = np.random.randint(0, dim_size - crop_dim + 1)
                coords.append((start, start + crop_dim))
                pads.append((0, 0))
            else:
                coords.append((0, dim_size))
                pads.append((0, crop_dim - dim_size))
        return coords, pads

    def _surface_biased_crop(self, label_vol, vol_shape):
        """
        Surface-Biased Rejection Samplingï¼ˆè¡¨é¢åå‘æ‹’ç»é‡‡æ ·ï¼‰

        ä»¥ pos_ratio çš„æ¦‚ç‡å¼ºåˆ¶é‡‡æ ·åˆ°å«æ­£æ ·æœ¬ï¼ˆå¢¨æ°´/çº¸å¼ ï¼‰çš„åŒºåŸŸï¼Œ
        å‰©ä½™æ¦‚ç‡è¿›è¡Œçº¯éšæœºé‡‡æ ·ï¼ˆè´Ÿæ ·æœ¬æŒ–æ˜ï¼‰ã€‚

        IO å®‰å…¨ä¿è¯ï¼š
          - label_vol æ˜¯ np.memmap å¯¹è±¡ï¼ˆmmap_mode='r'ï¼‰
          - label_vol[d0:d1, h0:h1, w0:w1] åˆ‡ç‰‡ä»…è§¦å‘ç¼ºé¡µä¸­æ–­ï¼Œ
            æ“ä½œç³»ç»Ÿåªè¯»å–å¯¹åº”é¡µé¢ï¼ˆ~0.25MBï¼‰ï¼Œä¸åŠ è½½æ•´ä¸ªä½“ç§¯
          - np.any() çŸ­è·¯æ±‚å€¼ï¼Œå‘½ä¸­é¦–ä¸ªéé›¶å…ƒç´ å³è¿”å›

        Args:
            label_vol: label ä½“ç§¯ï¼ˆmmap å¯¹è±¡æˆ– ndarrayï¼‰
            vol_shape: ä½“ç§¯çš„å½¢çŠ¶ (D, H, W)

        Returns:
            coords, pads: ä¸ _random_crop_coords æ ¼å¼ä¸€è‡´
        """
        force_positive = (np.random.rand() < self.pos_ratio)

        if force_positive:
            # æ‹’ç»é‡‡æ ·ï¼šæœ€å¤šé‡è¯• 10 æ¬¡å¯»æ‰¾å«æ­£æ ·æœ¬çš„ patch
            for _attempt in range(10):
                coords, pads = self._random_crop_coords(vol_shape)
                (d0, d1), (h0, h1), (w0, w1) = coords
                # å…³é”®: ä»…å¯¹ label mmap åšåˆ‡ç‰‡ peekï¼Œä¸åŠ è½½æ•´ä¸ªä½“ç§¯
                label_patch = label_vol[d0:d1, h0:h1, w0:w1]
                if np.any(label_patch == 1):
                    return coords, pads
            # 10 æ¬¡å…¨å¤±è´¥ï¼ˆæç½•è§ï¼‰ï¼Œæ¥å—æœ€åä¸€æ¬¡çš„éšæœºåæ ‡
            return coords, pads
        else:
            # è´Ÿæ ·æœ¬æŒ–æ˜ï¼šçº¯éšæœºè£å‰ª
            return self._random_crop_coords(vol_shape)

    def __getitem__(self, idx: int):
        """
        åŠ è½½ä½“ç§¯ â†’ éšæœºè£å‰ª â†’ å½’ä¸€åŒ– â†’ å¢å¼º â†’ Tensor

        Returns:
            image: (1, cD, cH, cW) float32 [0, 1]
            label: (1, cD, cH, cW) float32 {0, 1}
        """
        vol_idx = idx // self.samples_per_volume
        image_vol, label_vol = self._load_volume(vol_idx)

        # éšæœºè£å‰ªï¼ˆimage å’Œ label ç”¨ç›¸åŒåæ ‡ï¼‰
        # ä½¿ç”¨ Surface-Biased Rejection Sampling æ›¿ä»£çº¯éšæœºè£å‰ª
        coords, pads = self._surface_biased_crop(label_vol, image_vol.shape)
        (d0, d1), (h0, h1), (w0, w1) = coords

        # åˆ‡ç‰‡ + è½¬ float32ï¼ˆNPY mmap æ­¤æ—¶æ‰è§¦å‘çœŸæ­£çš„ç£ç›˜è¯»å–ï¼‰
        image = np.array(image_vol[d0:d1, h0:h1, w0:w1], dtype=np.float32)
        label = np.array(label_vol[d0:d1, h0:h1, w0:w1], dtype=np.float32)

        # Paddingï¼ˆä½“ç§¯å°äº crop_size æ—¶ï¼‰
        need_pad = any(p != (0, 0) for p in pads)
        if need_pad:
            image = np.pad(image, pads, mode='constant', constant_values=0)
            label = np.pad(label, pads, mode='constant', constant_values=0)

        # å½’ä¸€åŒ– image â†’ [0, 1]
        max_val = image.max()
        if max_val > 1.0:
            if max_val <= 255.0:
                image = image / 255.0
            else:
                image = image / 65535.0
        image = np.clip(image, 0.0, 1.0)

        # Label äºŒå€¼åŒ–ï¼ˆæ–¹æ¡ˆ Aï¼šåªè®¤ val=1 ä¸ºçº¸è‰è¡¨é¢ï¼Œval=2 ä¸ºå¿½ç•¥åŒºåŸŸå½“ä½œèƒŒæ™¯ï¼‰
        # ç«èµ›æ ‡ç­¾ï¼š0=èƒŒæ™¯, 1=çº¸è‰è¡¨é¢(ç›®æ ‡), 2=å¿½ç•¥/å¡«å……
        label = (label == 1).astype(np.float32)

        # å¢å¼ºå˜æ¢ï¼ˆä»… FlipRotateï¼ŒCrop å·²å®Œæˆï¼‰
        if self.transform is not None:
            image, label = self.transform(image, label)

        # è½¬ Tensor
        image_t = torch.from_numpy(np.ascontiguousarray(image)).unsqueeze(0)
        label_t = torch.from_numpy(np.ascontiguousarray(label)).unsqueeze(0)

        return image_t, label_t


if __name__ == "__main__":
    import time

    print("=== Dataset è‡ªæµ‹ ===")
    test_dir = Path("__test_tif_chunks__")
    test_dir.mkdir(exist_ok=True)

    try:
        # TifChunkDataset æµ‹è¯•
        for i in range(3):
            tifffile.imwrite(
                str(test_dir / f"chunk_{i:03d}.tif"),
                np.random.randint(0, 65535, (16, 32, 32), dtype=np.uint16)
            )
        ds = TifChunkDataset(test_dir)
        sample = ds[0]
        assert sample.shape == (1, 16, 32, 32)
        print("âœ“ TifChunkDataset é€šè¿‡ï¼")

        # VesuviusTrainDataset æµ‹è¯• (TIF æ¨¡å¼)
        img_dir = test_dir / "images"
        lbl_dir = test_dir / "labels"
        img_dir.mkdir(exist_ok=True)
        lbl_dir.mkdir(exist_ok=True)
        for i in range(5):
            tifffile.imwrite(str(img_dir / f"vol_{i:03d}.tif"),
                             np.random.randint(0, 255, (64, 64, 64), dtype=np.uint8))
            tifffile.imwrite(str(lbl_dir / f"vol_{i:03d}.tif"),
                             np.random.choice([0, 1, 2], (64, 64, 64)).astype(np.uint8))

        train_ds = VesuviusTrainDataset(
            img_dir, lbl_dir, crop_size=32, samples_per_volume=4, cache_size=5
        )

        t0 = time.time()
        for i in range(20):
            img, lbl = train_ds[i % len(train_ds)]
        t1 = time.time()
        print(f"TIF æ¨¡å¼: {(t1-t0)/20*1000:.1f}ms/sample, "
              f"image={img.shape}, label={lbl.shape}")

        # VesuviusTrainDataset æµ‹è¯• (NPY æ¨¡å¼)
        npy_img = test_dir / "images_npy"
        npy_lbl = test_dir / "labels_npy"
        npy_img.mkdir(exist_ok=True)
        npy_lbl.mkdir(exist_ok=True)
        for i in range(5):
            np.save(str(npy_img / f"vol_{i:03d}.npy"),
                    np.random.randint(0, 255, (64, 64, 64), dtype=np.uint8))
            np.save(str(npy_lbl / f"vol_{i:03d}.npy"),
                    np.random.choice([0, 1, 2], (64, 64, 64)).astype(np.uint8))

        npy_ds = VesuviusTrainDataset(
            img_dir, lbl_dir, crop_size=32, samples_per_volume=4
        )

        t0 = time.time()
        for i in range(20):
            img, lbl = npy_ds[i % len(npy_ds)]
        t1 = time.time()
        print(f"NPY æ¨¡å¼: {(t1-t0)/20*1000:.1f}ms/sample, "
              f"image={img.shape}, label={lbl.shape}")

        print("\nâœ“ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")

    finally:
        import shutil
        if test_dir.exists():
            shutil.rmtree(test_dir)

```

---
## File: 20_data\transforms.py
```py
"""
Vesuvius Challenge - 3D æ•°æ®å¢å¼ºå˜æ¢ (Phase 5)

ç”¨äº Patch-based è®­ç»ƒï¼šå¯¹ (image, label) é…å¯¹åŒæ­¥æ‰§è¡Œå˜æ¢ã€‚

ç»„ä»¶:
- RandomCrop3D:      ä»å¤§ä½“ç§¯ä¸­éšæœºè£å‰ªå›ºå®šå¤§å°çš„ 3D patch
- RandomFlipRotate3D: éšæœºç¿»è½¬ï¼ˆ3 è½´ï¼‰+ 90Â° æ—‹è½¬å¢å¼º
- Compose3D:         ç»„åˆå¤šä¸ªå˜æ¢
"""

import numpy as np
from typing import Tuple, List, Optional


class RandomCrop3D:
    """
    ä» (image, label) é…å¯¹ä¸­éšæœºè£å‰ª 3D patch

    Args:
        crop_size: è£å‰ªå°ºå¯¸ï¼Œint æˆ– (D, H, W) tuple
    """

    def __init__(self, crop_size=64):
        if isinstance(crop_size, int):
            self.crop_size = (crop_size, crop_size, crop_size)
        else:
            self.crop_size = tuple(crop_size)

    def __call__(
        self, image: np.ndarray, label: np.ndarray
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        Args:
            image: (D, H, W) float32
            label: (D, H, W) float32 æˆ– uint8

        Returns:
            image_crop, label_crop: è£å‰ªåçš„é…å¯¹
        """
        D, H, W = image.shape
        cD, cH, cW = self.crop_size

        # ç¡®ä¿ä½“ç§¯è¶³å¤Ÿå¤§
        if D < cD or H < cH or W < cW:
            # ä½“ç§¯ä¸å¤Ÿå¤§ï¼Œpad åˆ°åˆé€‚å°ºå¯¸
            pad_d = max(cD - D, 0)
            pad_h = max(cH - H, 0)
            pad_w = max(cW - W, 0)
            image = np.pad(image, ((0, pad_d), (0, pad_h), (0, pad_w)), mode='constant')
            label = np.pad(label, ((0, pad_d), (0, pad_h), (0, pad_w)), mode='constant')
            D, H, W = image.shape

        # éšæœºèµ·å§‹ä½ç½®
        d0 = np.random.randint(0, D - cD + 1)
        h0 = np.random.randint(0, H - cH + 1)
        w0 = np.random.randint(0, W - cW + 1)

        image_crop = image[d0:d0+cD, h0:h0+cH, w0:w0+cW]
        label_crop = label[d0:d0+cD, h0:h0+cH, w0:w0+cW]

        return image_crop, label_crop


class RandomFlipRotate3D:
    """
    éšæœº 3D ç¿»è½¬ + 90Â° æ—‹è½¬å¢å¼º

    å¯¹ (image, label) é…å¯¹åŒæ­¥æ“ä½œï¼Œä¿è¯ç©ºé—´ä¸€è‡´æ€§ã€‚

    Args:
        flip_prob: æ¯ä¸ªè½´ç¿»è½¬çš„æ¦‚ç‡ï¼Œé»˜è®¤ 0.5
        rotate_prob: æ‰§è¡Œ 90Â° æ—‹è½¬çš„æ¦‚ç‡ï¼Œé»˜è®¤ 0.5
    """

    def __init__(self, flip_prob: float = 0.5, rotate_prob: float = 0.5):
        self.flip_prob = flip_prob
        self.rotate_prob = rotate_prob

    def __call__(
        self, image: np.ndarray, label: np.ndarray
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        Args:
            image: (D, H, W)
            label: (D, H, W)

        Returns:
            image_aug, label_aug: å¢å¼ºåçš„é…å¯¹
        """
        # ç¡®ä¿ contiguous (é¿å…è´Ÿ stride é—®é¢˜)
        image = np.ascontiguousarray(image)
        label = np.ascontiguousarray(label)

        # éšæœºç¿»è½¬ 3 ä¸ªè½´
        for axis in range(3):
            if np.random.random() < self.flip_prob:
                image = np.flip(image, axis=axis)
                label = np.flip(label, axis=axis)

        # éšæœº 90Â° æ—‹è½¬ (åœ¨ H-W å¹³é¢)
        if np.random.random() < self.rotate_prob:
            k = np.random.randint(1, 4)  # æ—‹è½¬ 90Â°, 180Â°, 270Â°
            image = np.rot90(image, k=k, axes=(1, 2))
            label = np.rot90(label, k=k, axes=(1, 2))

        # ç¡®ä¿ contiguous
        image = np.ascontiguousarray(image)
        label = np.ascontiguousarray(label)

        return image, label


class Compose3D:
    """
    ç»„åˆå¤šä¸ª (image, label) é…å¯¹å˜æ¢

    Args:
        transforms: å˜æ¢åˆ—è¡¨ï¼Œæ¯ä¸ªå˜æ¢æ¥å— (image, label) è¿”å› (image, label)
    """

    def __init__(self, transforms: List):
        self.transforms = transforms

    def __call__(
        self, image: np.ndarray, label: np.ndarray
    ) -> Tuple[np.ndarray, np.ndarray]:
        for t in self.transforms:
            image, label = t(image, label)
        return image, label


if __name__ == "__main__":
    print("=== 3D Transforms è‡ªæµ‹ ===")

    # åˆæˆæ•°æ®
    image = np.random.rand(64, 128, 128).astype(np.float32)
    label = (image > 0.5).astype(np.float32)

    # æµ‹è¯• RandomCrop3D
    crop = RandomCrop3D(32)
    img_c, lbl_c = crop(image, label)
    assert img_c.shape == (32, 32, 32), f"Crop å½¢çŠ¶é”™è¯¯: {img_c.shape}"
    assert lbl_c.shape == (32, 32, 32), f"Label Crop å½¢çŠ¶é”™è¯¯: {lbl_c.shape}"
    print(f"  RandomCrop3D: {image.shape} â†’ {img_c.shape} âœ“")

    # æµ‹è¯• RandomFlipRotate3D
    aug = RandomFlipRotate3D()
    img_a, lbl_a = aug(img_c, lbl_c)
    assert img_a.shape == (32, 32, 32), f"Aug å½¢çŠ¶é”™è¯¯: {img_a.shape}"
    print(f"  RandomFlipRotate3D: {img_c.shape} â†’ {img_a.shape} âœ“")

    # æµ‹è¯• Compose3D
    pipeline = Compose3D([
        RandomCrop3D(32),
        RandomFlipRotate3D(),
    ])
    img_p, lbl_p = pipeline(image, label)
    assert img_p.shape == (32, 32, 32), f"Pipeline å½¢çŠ¶é”™è¯¯: {img_p.shape}"
    print(f"  Compose3D: {image.shape} â†’ {img_p.shape} âœ“")

    # æµ‹è¯•å°ä½“ç§¯ padding
    small_img = np.random.rand(16, 16, 16).astype(np.float32)
    small_lbl = (small_img > 0.5).astype(np.float32)
    crop64 = RandomCrop3D(32)
    img_s, lbl_s = crop64(small_img, small_lbl)
    assert img_s.shape == (32, 32, 32), f"Small vol crop é”™è¯¯: {img_s.shape}"
    print(f"  Small volume padding: (16,16,16) â†’ {img_s.shape} âœ“")

    print("âœ“ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")

```

---
## File: 20_model\__init__.py
```py
# 20_model: åŒå¤´ U-Net æ¨¡å‹ + å¤åˆæŸå¤±å‡½æ•°
from .dual_unet import DualHeadResUNet3D
from .chimera_loss import ChimeraLoss, compute_gt_normals

```

---
## File: 20_model\chimera_loss.py
```py
"""
Vesuvius Challenge - Chimera å¤åˆæŸå¤±å‡½æ•° (MVP)

L_total = L_Dice + Î»_normal Ã— L_CosineSimilarity

æ ¸å¿ƒç»„ä»¶ï¼š
1. DiceLoss: æ ‡å‡† Dice Lossï¼Œç”¨äºåˆ†å‰²å¤´
2. NormalCosineLoss: Cosine Similarity Lossï¼Œä»…åœ¨ mask åŒºåŸŸè®¡ç®—
3. compute_gt_normals(): ä» binary mask çš„ Sobel æ¢¯åº¦å®æ—¶ç”Ÿæˆæ³•çº¿ GT
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Tuple


def compute_gt_normals(mask: torch.Tensor) -> torch.Tensor:
    """
    ä» binary mask çš„æ¢¯åº¦å®æ—¶è®¡ç®—è¡¨é¢æ³•çº¿ Ground Truth

    ä½¿ç”¨ 3D Sobel ç®—å­è®¡ç®—æ¢¯åº¦æ–¹å‘ï¼Œç„¶åå½’ä¸€åŒ–ä¸ºå•ä½æ³•çº¿ã€‚
    æ³•çº¿æŒ‡å‘ä» papyrus å†…éƒ¨åˆ°å¤–éƒ¨çš„æ–¹å‘ã€‚

    Args:
        mask: åˆ†å‰²æ ‡ç­¾ï¼Œå½¢çŠ¶ (B, 1, D, H, W)ï¼Œå€¼åŸŸ {0, 1} æˆ– [0, 1]

    Returns:
        normals: æ³•çº¿ GTï¼Œå½¢çŠ¶ (B, 3, D, H, W)ï¼Œå•ä½å‘é‡
                 åœ¨éè¡¨é¢åŒºåŸŸï¼ˆæ¢¯åº¦ä¸ºé›¶ï¼‰ï¼Œæ³•çº¿ä¸º (0, 0, 0)
    """
    # ä½¿ç”¨ F.conv3d è®¡ç®— 3D æ¢¯åº¦ï¼ˆSobel ç®€åŒ–ç‰ˆ: ä¸­å¿ƒå·®åˆ†ï¼‰
    # æ¢¯åº¦æ ¸: æ²¿å„è½´çš„ä¸­å¿ƒå·®åˆ† [-1, 0, 1]
    device = mask.device
    dtype = mask.dtype

    # æ„å»ºæ¢¯åº¦å·ç§¯æ ¸
    # d æ–¹å‘æ¢¯åº¦ (depth/z)
    kernel_d = torch.zeros(1, 1, 3, 1, 1, device=device, dtype=dtype)
    kernel_d[0, 0, 0, 0, 0] = -1.0
    kernel_d[0, 0, 2, 0, 0] = 1.0

    # h æ–¹å‘æ¢¯åº¦ (height/y)
    kernel_h = torch.zeros(1, 1, 1, 3, 1, device=device, dtype=dtype)
    kernel_h[0, 0, 0, 0, 0] = -1.0
    kernel_h[0, 0, 0, 2, 0] = 1.0

    # w æ–¹å‘æ¢¯åº¦ (width/x)
    kernel_w = torch.zeros(1, 1, 1, 1, 3, device=device, dtype=dtype)
    kernel_w[0, 0, 0, 0, 0] = -1.0
    kernel_w[0, 0, 0, 0, 2] = 1.0

    # ä½¿ç”¨å¹³æ»‘åçš„ mask è®¡ç®—æ¢¯åº¦ï¼ˆé¿å…é”¯é½¿çŠ¶æ³•çº¿ï¼‰
    mask_smooth = mask.float()

    # è®¡ç®—ä¸‰ä¸ªæ–¹å‘çš„æ¢¯åº¦
    grad_d = F.conv3d(mask_smooth, kernel_d, padding=(1, 0, 0))
    grad_h = F.conv3d(mask_smooth, kernel_h, padding=(0, 1, 0))
    grad_w = F.conv3d(mask_smooth, kernel_w, padding=(0, 0, 1))

    # æ‹¼æ¥ä¸ºæ³•çº¿å‘é‡: (B, 3, D, H, W)
    normals = torch.cat([grad_d, grad_h, grad_w], dim=1)

    # å½’ä¸€åŒ–ä¸ºå•ä½å‘é‡
    norm = torch.norm(normals, dim=1, keepdim=True).clamp(min=1e-8)
    normals = normals / norm

    # æ¢¯åº¦ä¸ºé›¶çš„åŒºåŸŸï¼ˆéè¡¨é¢ï¼‰ï¼Œæ³•çº¿è®¾ä¸º (0, 0, 0)
    zero_mask = (norm < 1e-7).expand_as(normals)
    normals[zero_mask] = 0.0

    return normals


class DiceLoss(nn.Module):
    """
    æ ‡å‡† Dice Loss

    Dice = 2|Aâˆ©B| / (|A| + |B|)
    Loss = 1 - Dice
    """

    def __init__(self, smooth: float = 1e-6):
        super().__init__()
        self.smooth = smooth

    def forward(
        self,
        logits: torch.Tensor,
        targets: torch.Tensor,
    ) -> torch.Tensor:
        """
        Args:
            logits: åˆ†å‰² logitsï¼Œå½¢çŠ¶ (B, 1, D, H, W)
            targets: åˆ†å‰²æ ‡ç­¾ï¼Œå½¢çŠ¶ (B, 1, D, H, W)

        Returns:
            loss: æ ‡é‡ Dice Loss
        """
        probs = torch.sigmoid(logits)

        # å±•å¹³ä¸º (B, -1)
        probs_flat = probs.view(probs.size(0), -1)
        targets_flat = targets.view(targets.size(0), -1)

        # Dice ç³»æ•°
        intersection = (probs_flat * targets_flat).sum(dim=1)
        union = probs_flat.sum(dim=1) + targets_flat.sum(dim=1)

        dice = (2.0 * intersection + self.smooth) / (union + self.smooth)

        return (1.0 - dice).mean()


class NormalCosineLoss(nn.Module):
    """
    æ³•çº¿ Cosine Similarity Loss

    ä»…åœ¨ mask åŒºåŸŸï¼ˆè¡¨é¢é™„è¿‘ï¼‰è®¡ç®—ï¼Œå¿½ç•¥èƒŒæ™¯åŒºåŸŸçš„æ³•çº¿ã€‚
    Loss = 1 - mean(cos_sim) åœ¨ mask åŒºåŸŸ
    """

    def __init__(self):
        super().__init__()

    def forward(
        self,
        pred_normals: torch.Tensor,
        gt_normals: torch.Tensor,
        mask: torch.Tensor,
    ) -> torch.Tensor:
        """
        Args:
            pred_normals: é¢„æµ‹æ³•çº¿ï¼Œå½¢çŠ¶ (B, 3, D, H, W)ï¼Œå€¼åŸŸ [-1, 1]
            gt_normals: GT æ³•çº¿ï¼Œå½¢çŠ¶ (B, 3, D, H, W)
            mask: è¡¨é¢åŒºåŸŸæ©ç ï¼Œå½¢çŠ¶ (B, 1, D, H, W)

        Returns:
            loss: æ ‡é‡ Cosine Loss
        """
        # æ‰©å±• mask åˆ° 3 é€šé“
        mask_3ch = mask.expand_as(pred_normals)

        # åªåœ¨ mask åŒºåŸŸè®¡ç®— (æ¢¯åº¦éé›¶çš„åœ°æ–¹)
        # åŒæ—¶æ£€æŸ¥ GT æ³•çº¿éé›¶ï¼ˆåªåœ¨è¡¨é¢è®¡ç®—ï¼‰
        gt_norm = torch.norm(gt_normals, dim=1, keepdim=True)
        surface_mask = (mask > 0.5) & (gt_norm > 1e-6)
        surface_mask_3ch = surface_mask.expand_as(pred_normals)

        if surface_mask_3ch.sum() == 0:
            # æ²¡æœ‰è¡¨é¢åŒºåŸŸï¼Œé€šè¿‡ä¸ 0 ç›¸ä¹˜æ¥è¿”å› 0 æŸå¤±ï¼Œä¿æŒä¸è¾“å…¥å¼ é‡çš„æ¢¯åº¦é“¾
            # åŒæ—¶ç¡®ä¿ç»“æœæ˜¯ä¸€ä¸ªæ ‡é‡
            return pred_normals.sum() * 0.0

        # æå–è¡¨é¢åŒºåŸŸçš„æ³•çº¿
        # å°†æ³•çº¿ reshape ä¸º (N_surface, 3) è¿›è¡Œç‚¹ç§¯
        pred_masked = pred_normals[surface_mask_3ch].view(-1, 3)
        gt_masked = gt_normals[surface_mask_3ch].view(-1, 3)

        # Cosine similarity: dot(pred, gt) / (|pred| * |gt|)
        cos_sim = F.cosine_similarity(pred_masked, gt_masked, dim=1)

        # Loss = 1 - mean(cos_sim)
        loss = 1.0 - cos_sim.mean()

        return loss


class ChimeraLoss(nn.Module):
    """
    Chimera å¤åˆæŸå¤±å‡½æ•° (Updated with BCE)

    L_total = L_Dice + Î»_bce Ã— L_BCE + Î»_normal Ã— L_CosineSimilarity

    åŒæ—¶ç›‘ç£åƒç´ åˆ†ç±»ã€é‡å åŒºåŸŸå’Œæ³•çº¿é¢„æµ‹ã€‚
    BCE æ˜¯æ‰“ç ´â€œå…¨1é¢„æµ‹â€æ­»å¾ªç¯çš„å…³é”®ã€‚

    Args:
        lambda_normal: æ³•çº¿æŸå¤±çš„æƒé‡ç³»æ•°ï¼Œé»˜è®¤ 1.0
        lambda_bce:    BCE æŸå¤±çš„æƒé‡ç³»æ•°ï¼Œé»˜è®¤ 1.0
        dice_smooth:   Dice Loss çš„å¹³æ»‘ç³»æ•°
    """

    def __init__(
        self,
        lambda_normal: float = 1.0,
        lambda_bce: float = 1.0,
        dice_smooth: float = 1e-6,
        pos_weight: float = 10.0,
    ):
        super().__init__()
        self.lambda_normal = lambda_normal
        self.lambda_bce = lambda_bce
        self.dice_loss = DiceLoss(smooth=dice_smooth)
        # æ­£æ ·æœ¬åŠ æƒ (pos_weight)ï¼Œæ‰“ç ´"å…¨0"é™·é˜±
        # pos_weight=10.0: é€‚åº¦å¼ºè°ƒæ­£æ ·æœ¬ï¼Œå¹³è¡¡ Precision/Recall
        # pos_weight=100.0: æç«¯å¼ºè°ƒæ­£æ ·æœ¬ï¼ˆä¼šå¯¼è‡´é¢„æµ‹è†¨èƒ€ï¼‰
        pos_weight_tensor = torch.tensor([pos_weight])
        self.bce_loss = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)
        self.normal_loss = NormalCosineLoss()

    def forward(
        self,
        seg_logits: torch.Tensor,
        pred_normals: torch.Tensor,
        targets: torch.Tensor,
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        Args:
            seg_logits:    åˆ†å‰² logitsï¼Œå½¢çŠ¶ (B, 1, D, H, W)
            pred_normals:  é¢„æµ‹æ³•çº¿ï¼Œå½¢çŠ¶ (B, 3, D, H, W)
            targets:       åˆ†å‰²æ ‡ç­¾ï¼Œå½¢çŠ¶ (B, 1, D, H, W)

        Returns:
            total_loss:  L_Dice + Î»_bce * L_BCE + Î»_normal * L_Cosine
            dice_val:    Dice Loss åˆ†é‡
            bce_val:     BCE Loss åˆ†é‡
            normal_val:  Normal Cosine Loss åˆ†é‡
        """
        # 1. Dice Loss (é‡å åº¦)
        dice_val = self.dice_loss(seg_logits, targets)

        # 2. BCE Loss (åƒç´ çº§åˆ†ç±» - ä¸¥æƒ©èƒŒæ™¯è¯¯æŠ¥)
        # ç¡®ä¿ pos_weight åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        if self.bce_loss.pos_weight is not None and self.bce_loss.pos_weight.device != seg_logits.device:
            self.bce_loss.pos_weight = self.bce_loss.pos_weight.to(seg_logits.device)
            
        bce_val = self.bce_loss(seg_logits, targets.float())

        # 3. å®æ—¶è®¡ç®—æ³•çº¿ GT
        gt_normals = compute_gt_normals(targets)

        # 4. Normal Cosine Loss (å‡ ä½•)
        normal_val = self.normal_loss(pred_normals, gt_normals, targets)

        # 5. æ€»æŸå¤±
        total_loss = dice_val + (self.lambda_bce * bce_val) + (self.lambda_normal * normal_val)

        return total_loss, dice_val, bce_val, normal_val


if __name__ == "__main__":
    print("=== ChimeraLoss è‡ªæµ‹ ===")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    B, D, H, W = 2, 32, 32, 32

    # æ¨¡æ‹Ÿæ¨¡å‹è¾“å‡º (éœ€è¦è®¾ç½® requires_grad=True è¿›è¡Œ backward æµ‹è¯•)
    seg_logits = torch.randn(B, 1, D, H, W, device=device, requires_grad=True)
    pred_normals = torch.randn(B, 3, D, H, W, device=device, requires_grad=True).clamp(-1, 1)

    # åˆ›å»ºç®€å•çš„çƒå½¢æ ‡ç­¾
    zz, yy, xx = torch.meshgrid(
        torch.arange(D), torch.arange(H), torch.arange(W), indexing='ij'
    )
    dist = ((zz - D/2)**2 + (yy - H/2)**2 + (xx - W/2)**2).float().sqrt()
    sphere_mask = (dist < D * 0.3).float().unsqueeze(0).unsqueeze(0)  # (1, 1, D, H, W)
    targets = sphere_mask.expand(B, -1, -1, -1, -1).to(device)

    # æµ‹è¯• compute_gt_normals
    gt_normals = compute_gt_normals(targets)
    print(f"GT æ³•çº¿å½¢çŠ¶: {gt_normals.shape}")       # (B, 3, D, H, W)
    print(f"GT æ³•çº¿å€¼åŸŸ: [{gt_normals.min():.4f}, {gt_normals.max():.4f}]")

    # æµ‹è¯• ChimeraLoss
    criterion = ChimeraLoss(lambda_normal=1.0, lambda_bce=1.0)
    total, dice, bce, normal = criterion(seg_logits, pred_normals, targets)

    print(f"æ€»æŸå¤±:   {total.item():.4f}")
    print(f"Dice Loss: {dice.item():.4f}")
    print(f"BCE Loss:  {bce.item():.4f}")
    print(f"Normal:   {normal.item():.4f}")

    # åå‘ä¼ æ’­æµ‹è¯•
    print("æ­£åœ¨æµ‹è¯•åå‘ä¼ æ’­...")
    total.backward()
    print(f"Seg Logits Grad: {seg_logits.grad is not None}")
    print(f"Pred Normals Grad: {pred_normals.grad is not None}")
    print("âœ“ åå‘ä¼ æ’­é€šè¿‡ï¼")

    print("âœ“ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")

```

---
## File: 20_model\dual_unet.py
```py
"""
Vesuvius Challenge - åŒå¤´ Residual 3D U-Net (MVP)

Hybrid Chimera æ¶æ„çš„æ„ŸçŸ¥æ¨¡å—ï¼š
- Head A (Segmentation): è¾“å‡º (B,1,D,H,W)ï¼ŒSigmoid æ¿€æ´»ï¼Œæ¦‚ç‡å›¾
- Head B (Geometry):      è¾“å‡º (B,3,D,H,W)ï¼ŒTanh æ¿€æ´»ï¼Œæ³•çº¿å‘é‡ (nx,ny,nz)

è®¾è®¡é£æ ¼æ²¿ç”¨ src/model.py ä¸­ ResUNet3DWithAffinity çš„ Encoder-Decoder æ¨¡å¼ï¼Œ
ä½¿ç”¨ DoubleConv3D (Residual) + è½»é‡åŒ–é€šé“æ•° (base=16)ã€‚
"""

import torch
import torch.nn as nn
import torch.nn.functional as F


class DoubleConv3D(nn.Module):
    """
    3D åŒå·ç§¯å— + Residual Connection

    ç»“æ„: Input â†’ (Conv3dâ†’BNâ†’ReLU) Ã— 2 â†’ + Residual â†’ Output
    """

    def __init__(self, in_channels: int, out_channels: int):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm3d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm3d(out_channels),
        )
        self.relu = nn.ReLU(inplace=True)

        # æ®‹å·®è¿æ¥ï¼šé€šé“æ•°ä¸åŒæ—¶ç”¨ 1x1 å·ç§¯å¯¹é½
        if in_channels != out_channels:
            self.residual = nn.Sequential(
                nn.Conv3d(in_channels, out_channels, kernel_size=1, bias=False),
                nn.BatchNorm3d(out_channels),
            )
        else:
            self.residual = nn.Identity()

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.relu(self.conv(x) + self.residual(x))


class DualHeadResUNet3D(nn.Module):
    """
    åŒå¤´ Residual 3D U-Net

    Encoder: 4 å±‚ä¸‹é‡‡æ ·
    Decoder: 4 å±‚ä¸Šé‡‡æ · + Skip Connections
    è¾“å‡ºå¤´:
        - seg_head:    (B, 1, D, H, W) åˆ†å‰²æ¦‚ç‡å›¾
        - normal_head: (B, 3, D, H, W) è¡¨é¢æ³•çº¿å‘é‡

    Args:
        in_channels: è¾“å…¥é€šé“æ•°ï¼Œé»˜è®¤ 1ï¼ˆç°åº¦ CTï¼‰
        n_filters: åŸºç¡€æ»¤æ³¢å™¨æ•°é‡ï¼Œé»˜è®¤ 16ï¼ˆè½»é‡åŒ–è®¾è®¡ï¼‰
    """

    def __init__(self, in_channels: int = 1, n_filters: int = 16):
        super().__init__()

        # ===== Encoder (ä¸‹é‡‡æ ·) =====
        self.enc1 = DoubleConv3D(in_channels, n_filters)         # â†’ n
        self.pool1 = nn.MaxPool3d(2)

        self.enc2 = DoubleConv3D(n_filters, n_filters * 2)       # â†’ 2n
        # Anisotropic Pooling: ä¿æŠ¤ Z è½´åˆ†è¾¨ç‡ (D ä¿æŒä¸å˜)
        self.pool2 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))

        self.enc3 = DoubleConv3D(n_filters * 2, n_filters * 4)   # â†’ 4n
        self.pool3 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))

        self.enc4 = DoubleConv3D(n_filters * 4, n_filters * 8)   # â†’ 8n
        self.pool4 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))

        # ===== Bottleneck =====
        self.bottleneck = DoubleConv3D(n_filters * 8, n_filters * 16)  # â†’ 16n

        # ===== Decoder (ä¸Šé‡‡æ ·) =====
        # å¯¹åº” pool4: (1, 2, 2)
        self.up4 = nn.ConvTranspose3d(n_filters * 16, n_filters * 8, kernel_size=(1, 2, 2), stride=(1, 2, 2))
        self.dec4 = DoubleConv3D(n_filters * 16, n_filters * 8)   # concat: 8n + 8n

        # å¯¹åº” pool3: (1, 2, 2)
        self.up3 = nn.ConvTranspose3d(n_filters * 8, n_filters * 4, kernel_size=(1, 2, 2), stride=(1, 2, 2))
        self.dec3 = DoubleConv3D(n_filters * 8, n_filters * 4)    # concat: 4n + 4n

        # å¯¹åº” pool2: (1, 2, 2)
        self.up2 = nn.ConvTranspose3d(n_filters * 4, n_filters * 2, kernel_size=(1, 2, 2), stride=(1, 2, 2))
        self.dec2 = DoubleConv3D(n_filters * 4, n_filters * 2)    # concat: 2n + 2n

        # å¯¹åº” pool1: (2, 2, 2) -> ä¿æŒåŸæ ·
        self.up1 = nn.ConvTranspose3d(n_filters * 2, n_filters, kernel_size=2, stride=2)
        self.dec1 = DoubleConv3D(n_filters * 2, n_filters)        # concat: n + n

        # ===== åŒè¾“å‡ºå¤´ =====
        # Head A: åˆ†å‰²æ¦‚ç‡å›¾ (Sigmoid)
        self.seg_head = nn.Conv3d(n_filters, 1, kernel_size=1)

        # Head B: è¡¨é¢æ³•çº¿å‘é‡ (Tanh â†’ [-1, 1])
        self.normal_head = nn.Conv3d(n_filters, 3, kernel_size=1)

        # ===== è´Ÿåç½®åˆå§‹åŒ– =====
        # Sigmoid(-2.0) â‰ˆ 0.12ï¼Œå¼ºåˆ¶æ¨¡å‹åˆå§‹çŠ¶æ€é¢„æµ‹"èƒŒæ™¯"
        # é˜²æ­¢æ¨¡å‹ä¸€å¼€å§‹å°±é™·å…¥ Logitsâ‰ˆ0 (Sigmoidâ‰ˆ0.5) çš„èˆ’é€‚åŒº
        nn.init.constant_(self.seg_head.bias, -2.0)

    def forward(self, x: torch.Tensor):
        """
        å‰å‘ä¼ æ’­

        Args:
            x: è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ (B, 1, D, H, W)

        Returns:
            seg_logits: åˆ†å‰² logitsï¼Œå½¢çŠ¶ (B, 1, D, H, W)
                        ä¸‹æ¸¸ä½¿ç”¨ Sigmoid æˆ– BCEWithLogits å¤„ç†
            normals:    æ³•çº¿é¢„æµ‹ï¼Œå½¢çŠ¶ (B, 3, D, H, W)ï¼Œå€¼åŸŸ [-1, 1]
        """
        # --- Encoder ---
        e1 = self.enc1(x)       # (B, n, D, H, W)
        p1 = self.pool1(e1)

        e2 = self.enc2(p1)      # (B, 2n, D/2, H/2, W/2)
        p2 = self.pool2(e2)

        e3 = self.enc3(p2)      # (B, 4n, D/4, H/4, W/4)
        p3 = self.pool3(e3)

        e4 = self.enc4(p3)      # (B, 8n, D/8, H/8, W/8)
        p4 = self.pool4(e4)

        # --- Bottleneck ---
        b = self.bottleneck(p4)  # (B, 16n, D/16, H/16, W/16)

        # --- Decoder ---
        d4 = self.up4(b)
        d4 = torch.cat([d4, e4], dim=1)
        d4 = self.dec4(d4)

        d3 = self.up3(d4)
        d3 = torch.cat([d3, e3], dim=1)
        d3 = self.dec3(d3)

        d2 = self.up2(d3)
        d2 = torch.cat([d2, e2], dim=1)
        d2 = self.dec2(d2)

        d1 = self.up1(d2)
        d1 = torch.cat([d1, e1], dim=1)
        d1 = self.dec1(d1)      # (B, n, D, H, W) â€” å…±äº«ç‰¹å¾

        # --- åŒå¤´è¾“å‡º ---
        seg_logits = self.seg_head(d1)      # (B, 1, D, H, W) â€” raw logits
        normals = torch.tanh(self.normal_head(d1))  # (B, 3, D, H, W) â€” [-1, 1]

        return seg_logits, normals


if __name__ == "__main__":
    print("=== DualHeadResUNet3D è‡ªæµ‹ ===")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = DualHeadResUNet3D(in_channels=1, n_filters=16).to(device)

    # å‚æ•°é‡ç»Ÿè®¡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"æ€»å‚æ•°é‡: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°é‡: {trainable_params:,}")

    # å‰å‘ä¼ æ’­æµ‹è¯•
    # è¾“å…¥å°ºå¯¸å¿…é¡»èƒ½è¢« 16 æ•´é™¤ (4 å±‚ä¸‹é‡‡æ ·ï¼Œæ¯å±‚ /2)
    x = torch.randn(1, 1, 64, 64, 64, device=device)
    seg_logits, normals = model(x)

    print(f"è¾“å…¥å½¢çŠ¶:     {x.shape}")
    print(f"åˆ†å‰²è¾“å‡ºå½¢çŠ¶: {seg_logits.shape}")   # æœŸæœ› (1, 1, 64, 64, 64)
    print(f"æ³•çº¿è¾“å‡ºå½¢çŠ¶: {normals.shape}")       # æœŸæœ› (1, 3, 64, 64, 64)
    print(f"æ³•çº¿å€¼åŸŸ:     [{normals.min():.4f}, {normals.max():.4f}]")

    assert seg_logits.shape == (1, 1, 64, 64, 64), f"åˆ†å‰²è¾“å‡ºå½¢çŠ¶é”™è¯¯: {seg_logits.shape}"
    assert normals.shape == (1, 3, 64, 64, 64), f"æ³•çº¿è¾“å‡ºå½¢çŠ¶é”™è¯¯: {normals.shape}"
    assert normals.min() >= -1.0 and normals.max() <= 1.0, "æ³•çº¿å€¼åŸŸåº”åœ¨ [-1, 1]"

    print("âœ“ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")

```

---
## File: output\train_20260214_033543\training_history.json
```json
[
  {
    "epoch": 1,
    "lr": 0.001,
    "loss": 0.6997804939746857,
    "dice_loss": 0.6052835807204247,
    "normal_loss": 0.9449691474437714,
    "dice_score": 0.34815455228090286,
    "time": 2.958019256591797,
    "val_loss": 0.6592543125152588,
    "val_dice": 0.022845519706606865
  },
  {
    "epoch": 2,
    "lr": 0.000505,
    "loss": 0.5744479671120644,
    "dice_loss": 0.4918648824095726,
    "normal_loss": 0.8258308321237564,
    "dice_score": 0.44266364723443985,
    "time": 0.24978041648864746,
    "val_loss": 0.6520134210586548,
    "val_dice": 0.010394347831606865
  }
]
```

---
