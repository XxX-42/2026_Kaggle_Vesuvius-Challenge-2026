model:
  name: "MiniUNETR"
  in_channels: 1
  out_channels: 1
  feature_size: 16
  hidden_size: 384
  
training:
  batch_size: 2 # 初始值，AutoScaler 会自动调整
  lr: 1e-4  # Stage 5: 降低初始学习率以提供更稳健收敛
  min_lr: 1e-6  # 学习率衰减下限
  epochs: 60  # Stage 5: 延长训练周期
  mixed_precision: true
  grad_accumulation_steps: 8 # Effective Batch Size = 16
  val_interval: 1
  amp: true
  compile: false
  
  # 学习率调度器配置 (ReduceLROnPlateau)
  scheduler:
    name: "ReduceLROnPlateau"
    mode: "max"  # 监控 val_dice
    factor: 0.5  # 衰减系数
    patience: 3  # 容忍度
    min_lr: 1e-6
  
loss:
  name: "MaskedBCE"
  use_ignore_mask: true
  
data:
  num_workers: 0 # Windows Multiprocessing fails with large RAM cache. 0 is fast enough for RAM data.
  pin_memory: true
